{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Rare Variant Association Analysis with RVtests (ADNI)\n",
    "\n",
    "This notebook provides a full workflow for rare variant burden testing in the ADNI dataset using PLINK data with RVtests.\n",
    "\n",
    "## Workflow Overview\n",
    "\n",
    "### 1. Data Preparation & QC\n",
    "- Perform PLINK-based QC for rare (MAF 0.005–0.01) and common variants\n",
    "- LD pruning and PCA generation for population structure control\n",
    "- Generate phenotype, covariate, and keep files for AD vs CN baseline samples\n",
    "\n",
    "### 2. Dataset Conversion\n",
    "- Filter rare variant dataset to matched samples\n",
    "- Convert PLINK binary files to VCF, followed by compression and indexing\n",
    "\n",
    "### 3. Association Testing (RVtests)\n",
    "- Gene-based rare variant testing using:\n",
    "  - CMC (burden test)\n",
    "  - SKAT-O (kernel test)\n",
    "  - Variable Threshold (Price)\n",
    "- Adjusts for covariates (age, sex, education, APOE4, PCs)\n",
    "\n",
    "### 4. Post-Analysis\n",
    "- Aggregate and compare results across tests\n",
    "- Identify genes significant in multiple methods\n",
    "- Export summary statistics and significant findings\n",
    "\n",
    "### 5. Variant Extraction\n",
    "- Extract significant loci from VCF using bcftools\n",
    "- Apply allele frequency filters for rare variant validation\n",
    "- Generate RSID lists for candidate genes\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Citations\n",
    "\n",
    "> Petersen RC, et al. Alzheimer's Disease Neuroimaging Initiative. Alzheimers Dement. 2010 May;6(3):238-46. </p>\n",
    "> Xiaowei Zhan, et al. RVTESTS: An Efficient and Comprehensive Tool for Rare Variant Association Analysis Using Sequence Data. Bioinformatics. 2016 32: 1423-1426."
   ],
   "id": "8da654eba73d2b56"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 01 Data prepartion & QC\n",
    "i. PLINK QC for rare variants <br>\n",
    "ii. PLINK QC for common variants <br>\n",
    "iii. LD pruning <br>\n",
    "iv. PCA <br>\n",
    "v. Pheno & covar file creation <br>"
   ],
   "id": "f8ab22490f01f150"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 01_data_prep_qc\n",
    "# i. PLINK QC for rare variants\n",
    "\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "BFILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/01_data_prep_qc/inputs/ADNI_merged\"\n",
    "OUTPUT=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/01_data_prep_qc/outputs/rare_plink/ADNI2_rare\"\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "\n",
    "# ── QC rare variants ─────────────────────────────\n",
    "\n",
    "plink --bfile \"${BFILE}\" \\\n",
    "      --maf 0.005 \\\n",
    "      --max-maf 0.01 \\\n",
    "      --geno 0.05 \\\n",
    "      --mind 0.05 \\\n",
    "      --hwe 1e-6 \\\n",
    "      --mac 1 \\\n",
    "      --not-chr 0,M \\\n",
    "      --output-chr M \\\n",
    "      --make-bed \\\n",
    "      --out \"${OUTPUT}\"\n",
    "STATUS=$?\n",
    "\n",
    "if [ $STATUS -ne 0 ]; then\n",
    "  echo \"❌ ERROR: PLINK QC failed with exit code $STATUS\"\n",
    "  exit $STATUS\n",
    "fi\n",
    "\n",
    "echo \"✅ Files saved: ${OUTPUT}.[bed|bim|fam]\"\n",
    "echo \"🏁 QC (rare) complete.\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 01_data_prep_qc\n",
    "# ii. PLINK QC for common variants\n",
    "\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "BFILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/01_data_prep_qc/inputs/ADNI_merged\"\n",
    "OUTPUT=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/01_data_prep_qc/outputs/common_plink/ADNI2_common\"\n",
    "\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "\n",
    "# ── QC common variants ─────────────────────────────\n",
    "\n",
    "plink --bfile \"$BFILE\" \\\n",
    "      --maf 0.01 \\\n",
    "      --geno 0.05 \\\n",
    "      --mind 0.05 \\\n",
    "      --hwe 1e-6 \\\n",
    "      --mac 1 \\\n",
    "      --not-chr 0,M \\\n",
    "      --output-chr M \\\n",
    "      --make-bed \\\n",
    "      --out \"$OUTPUT\"\n",
    "STATUS=$?\n",
    "\n",
    "if [ $STATUS -ne 0 ]; then\n",
    "  echo \"❌ ERROR: PLINK QC failed with exit code $STATUS\"\n",
    "  exit $STATUS\n",
    "fi\n",
    "\n",
    "echo \"✅ Files saved: ${OUTPUT}.[bed|bim|fam]\"\n",
    "echo \"🏁 QC (common) complete.\""
   ],
   "id": "97e5eac48ea734c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 01_data_prep_qc\n",
    "# iii. LD pruning\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "BFILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/01_data_prep_qc/outputs/common_plink/ADNI2_common\"\n",
    "\n",
    "OUTPUT=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/01_data_prep_qc/outputs/LD_pruning/ADNI2_pruned\"\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "\n",
    "# ── LD pruning ─────────────────────────────\n",
    "\n",
    "plink \\\n",
    "  --bfile \"$BFILE\" \\\n",
    "  --indep-pairwise 200 50 0.3 \\\n",
    "  --out \"$OUTPUT\"\n",
    "STATUS=$?\n",
    "\n",
    "if [ $STATUS -ne 0 ]; then\n",
    "  echo \"❌ ERROR: PLINK QC failed with exit code $STATUS\"\n",
    "  exit $STATUS\n",
    "fi\n",
    "\n",
    "echo \"✅ Files saved: ${OUTPUT}\"\n",
    "echo \"🏁 LD pruning complete."
   ],
   "id": "8187b162e6009fe7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 01_data_prep_qc\n",
    "# iv. PCA generation on common variants set\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "BFILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/01_data_prep_qc/outputs/common_plink/ADNI2_common\"\n",
    "\n",
    "PRUNED=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/01_data_prep_qc/outputs/LD_pruning/ADNI2_pruned.prune.in\"\n",
    "\n",
    "OUTPUT=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/01_data_prep_qc/outputs/PCA/ADNI2_PCA\"\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "# ── PCA generation ─────────────────────────────\n",
    "\n",
    "plink \\\n",
    "  --bfile \"$BFILE\" \\\n",
    "  --extract \"$PRUNED\" \\\n",
    "  --pca 10 header \\\n",
    "  --out \"$OUTPUT\"\n",
    "STATUS=$?\n",
    "\n",
    "if [ $STATUS -ne 0 ]; then\n",
    "  echo \"❌ ERROR: PLINK QC failed with exit code $STATUS\"\n",
    "  exit $STATUS\n",
    "fi\n",
    "\n",
    "echo \"✅ Files saved: ${OUTPUT}\"\n",
    "echo \"🏁 PCA complete.\"\n"
   ],
   "id": "6cfb41b276cf899b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 01_data_prep_qc\n",
    "# v. Generate pheno and covar files\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "ADNI_MERGE_PATH = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\5. Rvtests\\01_data_prep_qc\\inputs\\ADNIMERGE_15May2025.csv\"\n",
    "PLINK_FAM_PATH  = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\5. Rvtests\\01_data_prep_qc\\outputs\\rare_plink\\ADNI2_rare.fam\"\n",
    "\n",
    "PCA_FILE = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\5. Rvtests\\01_data_prep_qc\\outputs\\PCA\\ADNI2_PCA.eigenvec\"\n",
    "\n",
    "OUTPUT_DIR = Path(r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\5. Rvtests\\01_data_prep_qc\\outputs\\pheno_covar\")\n",
    "\n",
    "NUM_PCS = 10  # Number of principal components to merge\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "# ── Load data  ─────────────────────────────\n",
    "\n",
    "def load_pca_data(pca_path, num_pcs):\n",
    "    print(f\"📖 Loading PCA data with {num_pcs} components...\")\n",
    "    pca_columns = [\"fid\", \"iid\"] + [f\"PC{i}\" for i in range(1, num_pcs + 1)]\n",
    "    pca = pd.read_csv(pca_path, sep=r'\\s+', header=0, names=pca_columns, dtype={\"fid\": str, \"iid\": str})\n",
    "    print(f\"✅ Loaded PCA data for {len(pca)} samples\")\n",
    "    return pca\n",
    "\n",
    "def save_keep_list(pheno_df, outdir):\n",
    "    keep_path = outdir / \"ADNI_AD_vs_CN.keep\"\n",
    "    pheno_df[['fid', 'iid']].to_csv(keep_path, sep='\\t', index=False, header=False)\n",
    "    print(f\"📄 Keep-list saved: {keep_path}\")\n",
    "    return keep_path\n",
    "\n",
    "def main():\n",
    "    print(\"📥 Loading ADNI phenotype and PLINK sample data...\")\n",
    "    adni_data = pd.read_csv(ADNI_MERGE_PATH, low_memory=False)\n",
    "    plink_fam = pd.read_csv(\n",
    "        PLINK_FAM_PATH, sep=r'\\s+', header=None,\n",
    "        names=['fid', 'iid', 'PAT', 'MAT', 'SEX', 'PHENOTYPE']\n",
    "    )\n",
    "\n",
    "    # ── Filter AD vs CN ─────────────────────────────\n",
    "    ad_cn_data = adni_data[(adni_data['VISCODE'] == 'bl') & (adni_data['DX_bl'].isin(['AD', 'CN']))].copy()\n",
    "    print(f\"🔍 Baseline AD vs CN: {len(ad_cn_data)} samples (before matching)\")\n",
    "\n",
    "    # ── Match PTIS and IIDM map FID ─────────────────────────────\n",
    "    ad_cn_data['iid'] = ad_cn_data['PTID'].astype(str)\n",
    "    ad_cn_data = ad_cn_data[ad_cn_data['iid'].isin(plink_fam['iid'].astype(str))]\n",
    "    iid_to_fid = dict(zip(plink_fam['iid'].astype(str), plink_fam['fid']))\n",
    "    ad_cn_data['fid'] = ad_cn_data['iid'].map(iid_to_fid)\n",
    "\n",
    "    if ad_cn_data['fid'].isnull().any():\n",
    "        missing = ad_cn_data[ad_cn_data['fid'].isnull()]['iid'].tolist()\n",
    "        print(\"⚠️ WARNING: Some samples could not be mapped to FIDs\")\n",
    "        print(f\"Missing FID for: {missing}\")\n",
    "\n",
    "    print(f\"✅ After genetic match: {len(ad_cn_data)} samples => \"\n",
    "          f\"{(ad_cn_data['DX_bl']=='AD').sum()} AD, {(ad_cn_data['DX_bl']=='CN').sum()} CN\")\n",
    "\n",
    "    # ── create phenotypes and covariates ─────────────────────────────\n",
    "    ad_cn_data['sex'] = ad_cn_data['PTGENDER'].map({'Male': 1, 'Female': 0})\n",
    "    ad_cn_data['age'] = ad_cn_data['AGE']\n",
    "    ad_cn_data['education'] = ad_cn_data['PTEDUCAT']\n",
    "    ad_cn_data['apoe4_count'] = ad_cn_data['APOE4']\n",
    "\n",
    "    phenotype_cols = ['fid', 'iid', 'DX_bl', 'age', 'sex', 'education', 'apoe4_count', 'PTID']\n",
    "    pheno_df = ad_cn_data[phenotype_cols].dropna(subset=['DX_bl', 'age', 'sex', 'education', 'apoe4_count'])\n",
    "    print(f\"🔍 Final sample size: {len(pheno_df)} \"\n",
    "          f\"({(pheno_df['DX_bl']=='AD').sum()} AD, {(pheno_df['DX_bl']=='CN').sum()} CN)\")\n",
    "\n",
    "    # ── merge with parentals IDs and numeric sex from FAM ─────────────────────────────\n",
    "    fam_cols = plink_fam[['fid', 'iid', 'PAT', 'MAT', 'SEX']].copy()\n",
    "    fam_cols.rename(columns={'PAT': 'fatid', 'MAT': 'matid', 'SEX': 'sex_fam'}, inplace=True)\n",
    "\n",
    "\n",
    "# ── PHENOTYPE FILE GENERATION (y1 = AD vs CN) ─────────────────────────────\n",
    "\n",
    "    pheno_merged = pd.merge(pheno_df, fam_cols, on=['fid', 'iid'], how='left')\n",
    "    pheno_merged['DX_bl'] = pheno_merged['DX_bl'].str.strip().str.upper()\n",
    "    pheno_merged['y1'] = pheno_merged['DX_bl'].map({'CN': 1, 'AD': 2}).astype('Int64')\n",
    "\n",
    "    pheno_final = pheno_merged[['fid', 'iid', 'fatid', 'matid', 'sex_fam', 'y1']].copy()\n",
    "    pheno_final.rename(columns={'sex_fam': 'sex'}, inplace=True)\n",
    "    pheno_final.to_csv(\n",
    "        OUTPUT_DIR / \"ADNI_AD_vs_CN.pheno\",\n",
    "        sep='\\t', index=False, na_rep='NA'\n",
    "    )\n",
    "\n",
    "\n",
    "# ── COVARIATE FILE GENERATION (covars + PCs, no duplicate sex) ─────────────────────────────\n",
    "\n",
    "    covar_base = pheno_df[['fid', 'iid', 'age', 'education', 'apoe4_count']].copy()\n",
    "    covar_merged = pd.merge(covar_base, fam_cols, on=['fid', 'iid'], how='left')\n",
    "\n",
    "    # Load PCA data\n",
    "    pca_df = load_pca_data(PCA_FILE, NUM_PCS)\n",
    "\n",
    "    # Merge covariates + PCA\n",
    "    covar_with_pcs = pd.merge(covar_merged, pca_df.drop(columns='fid'), on='iid', how='left')\n",
    "\n",
    "    # Reorder: fid iid fatid matid sex age education apoe4_count PC1...PCn\n",
    "    covar_final = covar_with_pcs[['fid', 'iid', 'fatid', 'matid', 'sex_fam',\n",
    "                                  'age', 'education', 'apoe4_count'] +\n",
    "                                 [f\"PC{i}\" for i in range(1, NUM_PCS + 1)]].copy()\n",
    "    covar_final.rename(columns={'sex_fam': 'sex'}, inplace=True)\n",
    "\n",
    "    covar_final.to_csv(\n",
    "        OUTPUT_DIR / \"ADNI_AD_vs_CN.covar\",\n",
    "        sep='\\t', index=False, na_rep='NA'\n",
    "    )\n",
    "\n",
    "    # Save keep-list file for PLINK\n",
    "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    keep_path = save_keep_list(pheno_df, OUTPUT_DIR)\n",
    "\n",
    "    # Save summary and stats\n",
    "    pheno_df.to_csv(\n",
    "        OUTPUT_DIR / \"ADNI_AD_vs_CN_summary.txt\",\n",
    "        sep='\\t', index=False, na_rep='NA'\n",
    "    )\n",
    "\n",
    "    summary_stats = pheno_df.groupby('DX_bl').agg({\n",
    "        'age': ['count', 'mean', 'std'],\n",
    "        'sex': 'mean',\n",
    "        'education': ['mean', 'std'],\n",
    "        'apoe4_count': ['mean', 'std']\n",
    "    }).round(2)\n",
    "\n",
    "    summary_stats.to_csv(\n",
    "        OUTPUT_DIR / \"ADNI_AD_vs_CN_summary_stats.txt\",\n",
    "        sep='\\t'\n",
    "    )\n",
    "\n",
    "    print(f\"\\n✅ Files saved to: {OUTPUT_DIR}\")\n",
    "    print(f\"✅ Phenotype file: {OUTPUT_DIR / 'ADNI_AD_vs_CN.pheno'}\")\n",
    "    print(f\"✅ Covariate file: {OUTPUT_DIR / 'ADNI_AD_vs_CN.covar'}\")\n",
    "    print(f\"🏁 Processing complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "697245036fb5eef3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 02 Dataset conversion\n",
    "i. Filter rare variant dataset to matched samples <br>\n",
    "ii. Convert to VCF (compression and indexing) <br>\n",
    "iii. Annotation (create annotated vcf to filer by variants)"
   ],
   "id": "4b325c8fff19715"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 02_dataset_conversion\n",
    "# i. filter plink rare to keep only samples with pheno data\n",
    "\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "BFILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/01_data_prep_qc/outputs/rare_plink/ADNI2_rare\"\n",
    "OUTPUT=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/02_dataset_conversion/ADNI2_AD_CN\"\n",
    "KEEP=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/01_data_prep_qc/outputs/pheno_covar/ADNI_AD_vs_CN.keep\"\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "\n",
    "# ── QC rare variants ─────────────────────────────\n",
    "\n",
    "plink --bfile \"$BFILE\" \\\n",
    "      --keep \"$KEEP\" \\\n",
    "      --make-bed \\\n",
    "      --out \"$OUTPUT\"\n",
    "STATUS=$?\n",
    "\n",
    "if [ $STATUS -ne 0 ]; then\n",
    "  echo \"❌ ERROR: PLINK QC failed with exit code $STATUS\"\n",
    "  exit $STATUS\n",
    "fi\n",
    "\n",
    "echo \"✅ Files saved: ${OUTPUT}.[bed|bim|fam]\"\n",
    "echo \"🏁 complete.\""
   ],
   "id": "6a7901ad34649917",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 02_dataset_conversion\n",
    "# ii. convert to compressed vcf + index\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "INPUT=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/02_dataset_conversion/ADNI2_AD_CN\"\n",
    "\n",
    "OUTPUT=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/02_dataset_conversion/ADNI2_AD_CN_converted\"\n",
    "\n",
    "VCF=\"${OUTPUT}.vcf\"\n",
    "\n",
    "BGZ=\"${VCF}.gz\"\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "# ── convert to vcf & compress + index ─────────────────────────────\n",
    "\n",
    "plink \\\n",
    "    --bfile \"${INPUT}\" \\\n",
    "    --recode vcf-iid \\\n",
    "    --out \"${OUTPUT}\"\n",
    "\n",
    "bgzip -f \"${VCF}\"\n",
    "tabix -p vcf \"${BGZ}\"\n",
    "\n",
    "echo \"✅ Files saved: ${BGZ} and ${BGZ}.tbi\"\n",
    "echo \"🏁 VCF conversion, compression, and indexing complete\"\n"
   ],
   "id": "f5117d9d6beaad2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 02_dataset_conversion [optional]\n",
    "# iii. produce annotated vcf file to filter variants on expression\n",
    "\n",
    "cd anno\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "INPUT_VCF=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/02_dataset_conversion/ADNI2_AD_CN_converted.vcf.gz\"\n",
    "OUTPUT_VCF=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/02_dataset_conversion/annotation/ADNI2_AD_CN_anno.vcf.gz\"\n",
    "REFERENCE_FA=\"/home/swmitchell/anno/resources/hs37d5.fa\"\n",
    "GENE_ANNOTATION=\"/home/swmitchell/anno/resources/refFlat_hg19.txt.gz\"\n",
    "PRIORITY_FILE=\"/home/swmitchell/anno/resources/priority.txt\"\n",
    "CODON_FILE=\"/home/swmitchell/anno/resources/codon.txt\"\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "./executable/anno \\\n",
    "  -i \"$INPUT_VCF\" \\\n",
    "  -o \"$OUTPUT_VCF\" \\\n",
    "  -r \"$REFERENCE_FA\" \\\n",
    "  -g \"$GENE_ANNOTATION\" \\\n",
    "  -p \"$PRIORITY_FILE\" \\\n",
    "  -c \"$CODON_FILE\" \\\n",
    "  --indexOutput"
   ],
   "id": "9943743b8daa45f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 03 Association Testing (RVtests)\n",
    "i. Gene-based rare variant testing using:\n",
    "  - CMC (burden test)\n",
    "  - SKAT-O (kernel test)\n",
    "  - Variable Threshold (Price)"
   ],
   "id": "46449d8013000deb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#rvtest\n",
    "\n",
    "#groupwise tests\n",
    "# example\n",
    "\n",
    "rvtest --inVcf rarevariants.vcf.gz \\\n",
    "   --pheno pheno.ped \\\n",
    "   --out output \\\n",
    "   --geneFile refFlat_hg19.txt.gz \\ # to specify the gene range in a refFlat format\n",
    "   --burden cmc \\ # collapsing and combine rare variants\n",
    "   --vt price \\\n",
    "   --kernel skato \\\n",
    "   --covar example.covar \\\n",
    "   --covar-name age,sex,education,apoe4_count,PC1,PC2,PC3,PC4,PC5,PC6,PC7,PC8,PC9,PC10 \\\n",
    "   --freqUpper 0.01 \\ # Specify upper minor allele frequency bound to be included in analysis\n",
    "   --freqLower 0.001 \\ # Specify lower minor allele frequency bound to be included in analysis\n"
   ],
   "id": "103860d3cc80432",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 02_rvtests\n",
    "# i. run Rvtests\n",
    "\n",
    "cd rvtests\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "# use normal vcf for non-annotation run\n",
    "INVCF=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/02_dataset_conversion/ADNI2_AD_CN_converted.vcf.gz\"\n",
    "\n",
    "# if filtering based on annotation, need annotated vcf\n",
    "#INVCF=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/02_dataset_conversion/annotation/ADNI2_AD_CN_anno.vcf.gz\"\n",
    "\n",
    "PHENO=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/01_data_prep_qc/outputs/pheno_covar/ADNI_AD_vs_CN.pheno\"\n",
    "\n",
    "COVAR=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/01_data_prep_qc/outputs/pheno_covar/ADNI_AD_vs_CN.covar\"\n",
    "\n",
    "GENEFILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/03_rvtests/inputs/refFlat.txt.gz\"\n",
    "\n",
    "OUTDIR=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/03_rvtests/outputs\"\n",
    "\n",
    "OUTFILE=\"${OUTDIR}/ADNI2_rvtest\"\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "# ── run rvtests ─────────────────────────────\n",
    "\n",
    "./executable/rvtest \\\n",
    "  --inVcf \"$INVCF\" \\\n",
    "  --pheno \"$PHENO\" \\\n",
    "  --out \"$OUTFILE\" \\\n",
    "  --geneFile \"$GENEFILE\" \\\n",
    "  --burden cmc \\\n",
    "  --vt price \\\n",
    "  --kernel skato \\\n",
    "  --covar \"$COVAR\" \\\n",
    "  --covar-name age,sex,education,apoe4_count,PC1,PC2,PC3,PC4,PC5,PC6,PC7,PC8,PC9,PC10 \\\n",
    "  --freqUpper 0.01 \\\n",
    "  --freqLower 0.005 \\\n",
    "  --noweb \\\n",
    " # --annoType Start_Gain|Stop_Loss|Start_Loss|Essential_Splice_Site|Stop_Gain|Normal_Splice_Site|Synonymous|Nonsynonymous \\ #filter variants based on annotation\n",
    "  --outputRaw\n",
    "\n"
   ],
   "id": "9532e19b3982fed4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 04 Post-Analysis\n",
    "- Aggregate and compare results across tests\n",
    "- Identify genes significant in multiple methods\n",
    "- Export summary statistics and significant findings\n"
   ],
   "id": "7c64d579e68d6ec5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T00:12:08.736309Z",
     "start_time": "2025-09-03T00:12:00.788107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 03_post_analysis\n",
    "# Processes CMC, SKAT-O, and Variable Threshold Price test results,\n",
    "# Identifies significant genes for further investigation.\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "# Input file paths\n",
    "CMC_FILE = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\5. Rvtests\\03_rvtests\\outputs\\ADNI2_rvtest.CMC.assoc\"\n",
    "SKATO_FILE = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\5. Rvtests\\03_rvtests\\outputs\\ADNI2_rvtest.SkatO.assoc\"\n",
    "VT_FILE = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\5. Rvtests\\03_rvtests\\outputs\\ADNI2_rvtest.VariableThresholdPrice.assoc\"\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = Path(r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\5. Rvtests\\04_post_analysis\")\n",
    "\n",
    "# Significance thresholds\n",
    "HIGHLY_SIGNIFICANT_THRESHOLD = 0.001\n",
    "SIGNIFICANT_THRESHOLD = 0.01\n",
    "SUGGESTIVE_THRESHOLD = 0.05\n",
    "PRIMARY_THRESHOLD = 0.05  # Primary reporting threshold\n",
    "\n",
    "# Display settings\n",
    "TOP_RESULTS_TO_SHOW = 20\n",
    "MAX_GENES_TO_LIST = 10\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "# ── Load and process results ─────────────────────────────\n",
    "def load_and_process_files(cmc_file, skato_file, vt_file):\n",
    "    \"\"\"Load and process the three rare variant test result files.\"\"\"\n",
    "    results = {}\n",
    "    try:\n",
    "        cmc_df = pd.read_csv(cmc_file, sep='\\t')\n",
    "        cmc_df['Test_Type'] = 'CMC'\n",
    "        cmc_df['P_value'] = cmc_df['Pvalue']\n",
    "        results['CMC'] = cmc_df\n",
    "        print(f\"📂 Loaded CMC file: {len(cmc_df)} genes\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading CMC file: {e}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        skato_df = pd.read_csv(skato_file, sep='\\t')\n",
    "        skato_df['Test_Type'] = 'SKAT-O'\n",
    "        skato_df['P_value'] = skato_df['Pvalue']\n",
    "        results['SKAT-O'] = skato_df\n",
    "        print(f\"📂 Loaded SKAT-O file: {len(skato_df)} genes\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading SKAT-O file: {e}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        vt_df = pd.read_csv(vt_file, sep='\\t')\n",
    "        vt_df['Test_Type'] = 'Variable_Threshold'\n",
    "        vt_df['P_value'] = vt_df['PermPvalue']\n",
    "        results['Variable_Threshold'] = vt_df\n",
    "        print(f\"📂 Loaded Variable Threshold file: {len(vt_df)} genes\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading Variable Threshold file: {e}\")\n",
    "        return None\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ── Significance metrics ─────────────────────────────\n",
    "def calculate_significance_metrics(df, p_col='P_value'):\n",
    "    \"\"\"Calculate -log10(p) values and assign significance categories.\"\"\"\n",
    "    df = df.copy()\n",
    "    df['neg_log10_p'] = -np.log10(df[p_col].replace(0, 1e-300))  # handle p=0\n",
    "    df['significance_level'] = pd.cut(\n",
    "        df[p_col],\n",
    "        bins=[0, HIGHLY_SIGNIFICANT_THRESHOLD, SIGNIFICANT_THRESHOLD, SUGGESTIVE_THRESHOLD, 1.0],\n",
    "        labels=['Highly_Significant', 'Significant', 'Suggestive', 'Not_Significant'],\n",
    "        include_lowest=True\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "# ── Merge results ─────────────────────────────\n",
    "def merge_results(results_dict):\n",
    "    \"\"\"Merge results from all three tests into a single dataframe.\"\"\"\n",
    "    merged_results = []\n",
    "    for test_type, df in results_dict.items():\n",
    "        if test_type == 'CMC':\n",
    "            cols = ['Gene', 'RANGE', 'N_INFORMATIVE', 'NumVar', 'NumPolyVar',\n",
    "                    'NonRefSite', 'P_value', 'Test_Type', 'neg_log10_p', 'significance_level']\n",
    "        elif test_type == 'SKAT-O':\n",
    "            cols = ['Gene', 'RANGE', 'N_INFORMATIVE', 'NumVar', 'NumPolyVar',\n",
    "                    'Q', 'rho', 'P_value', 'Test_Type', 'neg_log10_p', 'significance_level']\n",
    "        else:  # Variable Threshold\n",
    "            cols = ['Gene', 'RANGE', 'N_INFORMATIVE', 'NumVar', 'NumPolyVar',\n",
    "                    'OptFreq', 'Zmax', 'Stat', 'P_value', 'Test_Type', 'neg_log10_p', 'significance_level']\n",
    "\n",
    "        available_cols = [col for col in cols if col in df.columns]\n",
    "        merged_results.append(df[available_cols])\n",
    "\n",
    "    combined_df = pd.concat(merged_results, ignore_index=True, sort=False)\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "# ── Gene-level aggregation ─────────────────────────────\n",
    "def find_best_result_per_gene(combined_df):\n",
    "    \"\"\"Select the best (lowest p-value) result per gene.\"\"\"\n",
    "    best_results = combined_df.loc[combined_df.groupby('Gene')['P_value'].idxmin()].copy()\n",
    "    return best_results.sort_values('P_value')\n",
    "\n",
    "\n",
    "# ── Cross-test significance ─────────────────────────────\n",
    "def analyze_cross_test_significance(combined_df, threshold=PRIMARY_THRESHOLD):\n",
    "    \"\"\"Analyse cross-test significance for each gene.\"\"\"\n",
    "    gene_test_matrix = combined_df.pivot(index='Gene', columns='Test_Type', values='P_value')\n",
    "    significant_counts = (gene_test_matrix < threshold).sum(axis=1)\n",
    "\n",
    "    all_tests_sig = significant_counts[significant_counts == 3].index.tolist()\n",
    "    two_tests_sig = significant_counts[significant_counts == 2].index.tolist()\n",
    "    one_test_sig = significant_counts[significant_counts == 1].index.tolist()\n",
    "\n",
    "    cross_test_results = []\n",
    "    for gene in combined_df['Gene'].unique():\n",
    "        gene_data = combined_df[combined_df['Gene'] == gene]\n",
    "        result = {'Gene': gene}\n",
    "        if 'RANGE' in gene_data: result['RANGE'] = gene_data['RANGE'].iloc[0]\n",
    "        if 'N_INFORMATIVE' in gene_data: result['N_INFORMATIVE'] = gene_data['N_INFORMATIVE'].iloc[0]\n",
    "        if 'NumVar' in gene_data: result['NumVar'] = gene_data['NumVar'].iloc[0]\n",
    "        if 'NumPolyVar' in gene_data: result['NumPolyVar'] = gene_data['NumPolyVar'].iloc[0]\n",
    "\n",
    "        for test_type in ['CMC', 'SKAT-O', 'Variable_Threshold']:\n",
    "            test_data = gene_data[gene_data['Test_Type'] == test_type]\n",
    "            if len(test_data) > 0:\n",
    "                p_val = test_data['P_value'].iloc[0]\n",
    "                result[f'{test_type}_pval'] = p_val\n",
    "                result[f'{test_type}_sig'] = 'Yes' if p_val < threshold else 'No'\n",
    "            else:\n",
    "                result[f'{test_type}_pval'] = np.nan\n",
    "                result[f'{test_type}_sig'] = 'N/A'\n",
    "\n",
    "        result['Tests_Significant'] = sum([1 for test in ['CMC', 'SKAT-O', 'Variable_Threshold']\n",
    "                                           if result[f'{test}_sig'] == 'Yes'])\n",
    "        result['Min_Pvalue'] = min([result[f'{test}_pval']\n",
    "                                    for test in ['CMC', 'SKAT-O', 'Variable_Threshold']\n",
    "                                    if not pd.isna(result[f'{test}_pval'])])\n",
    "        cross_test_results.append(result)\n",
    "\n",
    "    cross_test_df = pd.DataFrame(cross_test_results)\n",
    "    cross_test_df = cross_test_df.sort_values(['Tests_Significant', 'Min_Pvalue'], ascending=[False, True])\n",
    "    return cross_test_df, all_tests_sig, two_tests_sig, one_test_sig\n",
    "\n",
    "\n",
    "# ── Reporting ─────────────────────────────\n",
    "def generate_summary_report(results_dict, combined_df, best_results, cross_test_df,\n",
    "                            all_tests_sig, two_tests_sig, one_test_sig):\n",
    "    \"\"\"Console summary of rare variant testing results.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RARE VARIANT TESTING RESULTS SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Significance thresholds:\")\n",
    "    print(f\"  - Highly significant: p < {HIGHLY_SIGNIFICANT_THRESHOLD}\")\n",
    "    print(f\"  - Significant: p < {SIGNIFICANT_THRESHOLD}\")\n",
    "    print(f\"  - Suggestive: p < {SUGGESTIVE_THRESHOLD}\")\n",
    "    print(f\"  - Primary threshold: p < {PRIMARY_THRESHOLD}\")\n",
    "\n",
    "    print(f\"\\n🔍 Overall statistics:\")\n",
    "    print(f\"Total unique genes analysed: {len(combined_df['Gene'].unique())}\")\n",
    "    print(f\"Total test results processed: {len(combined_df)}\")\n",
    "\n",
    "    print(f\"\\n🧪 Results by test type:\")\n",
    "    for test_type in ['CMC', 'SKAT-O', 'Variable_Threshold']:\n",
    "        test_df = combined_df[combined_df['Test_Type'] == test_type]\n",
    "        sig_count = len(test_df[test_df['P_value'] < PRIMARY_THRESHOLD])\n",
    "        print(f\" - {test_type}: {len(test_df)} genes, {sig_count} significant\")\n",
    "\n",
    "    print(f\"\\n📊 Cross-test significance analysis:\")\n",
    "    print(f\"Genes significant in all 3 tests: {len(all_tests_sig)}\")\n",
    "    print(f\"Genes significant in 2 tests: {len(two_tests_sig)}\")\n",
    "    print(f\"Genes significant in 1 test: {len(one_test_sig)}\")\n",
    "\n",
    "    print(f\"\\n📌 Significance summary (best result per gene):\")\n",
    "    sig_summary = best_results['significance_level'].value_counts()\n",
    "    for level in ['Highly_Significant', 'Significant', 'Suggestive', 'Not_Significant']:\n",
    "        print(f\" - {level}: {sig_summary.get(level, 0)} genes\")\n",
    "\n",
    "    print(f\"\\n🏆 Top {TOP_RESULTS_TO_SHOW} results:\")\n",
    "    display_cols = ['Gene', 'Test_Type', 'P_value', 'neg_log10_p', 'NumVar', 'NumPolyVar']\n",
    "    sig_results = best_results[best_results['P_value'] < PRIMARY_THRESHOLD]\n",
    "    if len(sig_results) > 0:\n",
    "        print(sig_results[display_cols].head(TOP_RESULTS_TO_SHOW).to_string(index=False, float_format='%.2e'))\n",
    "    else:\n",
    "        print(\"No significant results found.\")\n",
    "        print(best_results[display_cols].head(TOP_RESULTS_TO_SHOW).to_string(index=False, float_format='%.2e'))\n",
    "\n",
    "\n",
    "# ── Save outputs ─────────────────────────────\n",
    "def save_results(combined_df, best_results, cross_test_df, output_dir):\n",
    "    \"\"\"Save results to CSV in specified output directory.\"\"\"\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    combined_df.to_csv(output_path / \"all_rare_variant_results.csv\", index=False)\n",
    "    best_results.to_csv(output_path / \"best_results_per_gene.csv\", index=False)\n",
    "    cross_test_df.to_csv(output_path / \"cross_test_significance_analysis.csv\", index=False)\n",
    "\n",
    "    significant_results = best_results[best_results['P_value'] < PRIMARY_THRESHOLD]\n",
    "    if len(significant_results) > 0:\n",
    "        significant_results.to_csv(output_path / \"significant_results.csv\", index=False)\n",
    "\n",
    "    multi_test_sig = cross_test_df[cross_test_df['Tests_Significant'] >= 2]\n",
    "    if len(multi_test_sig) > 0:\n",
    "        multi_test_sig.to_csv(output_path / \"multi_test_significant_genes.csv\", index=False)\n",
    "\n",
    "    print(f\"\\n✅ Results saved to: {output_dir}\")\n",
    "    return output_path\n",
    "\n",
    "\n",
    "# ── Main ─────────────────────────────\n",
    "def main():\n",
    "    # Check files exist\n",
    "    for file_path in [CMC_FILE, SKATO_FILE, VT_FILE]:\n",
    "        if not Path(file_path).exists():\n",
    "            print(f\"❌ Error: File not found - {file_path}\")\n",
    "            return\n",
    "\n",
    "    print(\"📥 Loading result files...\")\n",
    "    results_dict = load_and_process_files(CMC_FILE, SKATO_FILE, VT_FILE)\n",
    "    if results_dict is None:\n",
    "        print(\"❌ Failed to load one or more input files. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Process input datasets\n",
    "    for test_type, df in results_dict.items():\n",
    "        results_dict[test_type] = calculate_significance_metrics(df)\n",
    "\n",
    "    print(\"\\n🔄 Merging results...\")\n",
    "    combined_df = merge_results(results_dict)\n",
    "\n",
    "    print(\"⭐ Selecting best result per gene...\")\n",
    "    best_results = find_best_result_per_gene(combined_df)\n",
    "\n",
    "    print(\"🔗 Analysing cross-test significance...\")\n",
    "    cross_test_df, all_tests_sig, two_tests_sig, one_test_sig = analyze_cross_test_significance(combined_df)\n",
    "\n",
    "    # Console summary\n",
    "    generate_summary_report(results_dict, combined_df, best_results, cross_test_df,\n",
    "                            all_tests_sig, two_tests_sig, one_test_sig)\n",
    "\n",
    "    # Save\n",
    "    output_path = save_results(combined_df, best_results, cross_test_df, OUTPUT_DIR)\n",
    "\n",
    "    print(\"\\n🏁 Analysis complete.\")\n",
    "    print(f\"- {len(all_tests_sig)} genes significant in ALL tests\")\n",
    "    print(f\"- {len(two_tests_sig)} genes significant in 2 tests\")\n",
    "    print(f\"- {len(one_test_sig)} genes significant in 1 test\")\n",
    "    print(f\"\\n📌 Priority genes (>=2 tests significant):\")\n",
    "    priority_genes = cross_test_df[cross_test_df['Tests_Significant'] >= 2]['Gene'].tolist()\n",
    "    if priority_genes:\n",
    "        for i, gene in enumerate(priority_genes[:MAX_GENES_TO_LIST], 1):\n",
    "            gene_info = cross_test_df[cross_test_df['Gene'] == gene].iloc[0]\n",
    "            print(f\"{i}. {gene} ({gene_info['Tests_Significant']} tests, min p = {gene_info['Min_Pvalue']:.2e})\")\n",
    "        if len(priority_genes) > MAX_GENES_TO_LIST:\n",
    "            print(f\"... and {len(priority_genes) - MAX_GENES_TO_LIST} more genes.\")\n",
    "    else:\n",
    "        print(\"No multi-test significant genes detected.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "f8e5cf13e3104344",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Loading result files...\n",
      "📂 Loaded CMC file: 3586 genes\n",
      "📂 Loaded SKAT-O file: 3586 genes\n",
      "📂 Loaded Variable Threshold file: 3586 genes\n",
      "\n",
      "🔄 Merging results...\n",
      "⭐ Selecting best result per gene...\n",
      "🔗 Analysing cross-test significance...\n",
      "\n",
      "================================================================================\n",
      "RARE VARIANT TESTING RESULTS SUMMARY\n",
      "================================================================================\n",
      "Significance thresholds:\n",
      "  - Highly significant: p < 0.001\n",
      "  - Significant: p < 0.01\n",
      "  - Suggestive: p < 0.05\n",
      "  - Primary threshold: p < 0.05\n",
      "\n",
      "🔍 Overall statistics:\n",
      "Total unique genes analysed: 3586\n",
      "Total test results processed: 10758\n",
      "\n",
      "🧪 Results by test type:\n",
      " - CMC: 3586 genes, 192 significant\n",
      " - SKAT-O: 3586 genes, 191 significant\n",
      " - Variable_Threshold: 3586 genes, 123 significant\n",
      "\n",
      "📊 Cross-test significance analysis:\n",
      "Genes significant in all 3 tests: 41\n",
      "Genes significant in 2 tests: 125\n",
      "Genes significant in 1 test: 133\n",
      "\n",
      "📌 Significance summary (best result per gene):\n",
      " - Highly_Significant: 1 genes\n",
      " - Significant: 33 genes\n",
      " - Suggestive: 265 genes\n",
      " - Not_Significant: 3287 genes\n",
      "\n",
      "🏆 Top 20 results:\n",
      "        Gene          Test_Type  P_value  neg_log10_p  NumVar  NumPolyVar\n",
      "      CDCA7L                CMC 8.77e-04     3.06e+00       1           1\n",
      "       MGAT5 Variable_Threshold 1.50e-03     2.82e+00       2           2\n",
      "   LINC01619             SKAT-O 1.55e-03     2.81e+00       1           1\n",
      "       NR4A3                CMC 1.96e-03     2.71e+00       1           1\n",
      "       DNAH8                CMC 2.09e-03     2.68e+00       4           4\n",
      "      DLGAP1             SKAT-O 2.25e-03     2.65e+00       7           7\n",
      "BORCS8-MEF2B             SKAT-O 2.47e-03     2.61e+00       2           2\n",
      "        ZHX3                CMC 2.71e-03     2.57e+00       1           1\n",
      "       BSPRY                CMC 2.76e-03     2.56e+00       1           1\n",
      "      MYBPC1                CMC 2.78e-03     2.56e+00       1           1\n",
      "      NT5DC1                CMC 2.92e-03     2.54e+00       3           3\n",
      "   RAB11FIP4                CMC 3.97e-03     2.40e+00       1           1\n",
      "       BACH2 Variable_Threshold 4.95e-03     2.31e+00       2           2\n",
      "       ITPR2             SKAT-O 5.13e-03     2.29e+00       2           2\n",
      "       CRIM1                CMC 5.32e-03     2.27e+00       1           1\n",
      "       FARP2 Variable_Threshold 5.50e-03     2.26e+00       2           2\n",
      "     RUNDC3B             SKAT-O 5.51e-03     2.26e+00       3           3\n",
      "      ZFAND3             SKAT-O 5.56e-03     2.25e+00       2           2\n",
      "  DLGAP1-AS5                CMC 5.68e-03     2.25e+00       1           1\n",
      "       KCNQ1 Variable_Threshold 6.20e-03     2.21e+00       2           2\n",
      "\n",
      "✅ Results saved to: C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\5. Rvtests\\04_post_analysis\n",
      "\n",
      "🏁 Analysis complete.\n",
      "- 41 genes significant in ALL tests\n",
      "- 125 genes significant in 2 tests\n",
      "- 133 genes significant in 1 test\n",
      "\n",
      "📌 Priority genes (>=2 tests significant):\n",
      "1. MGAT5 (3 tests, min p = 1.50e-03)\n",
      "2. DLGAP1 (3 tests, min p = 2.25e-03)\n",
      "3. BORCS8-MEF2B (3 tests, min p = 2.47e-03)\n",
      "4. ZHX3 (3 tests, min p = 2.71e-03)\n",
      "5. MYBPC1 (3 tests, min p = 2.78e-03)\n",
      "6. NT5DC1 (3 tests, min p = 2.92e-03)\n",
      "7. RAB11FIP4 (3 tests, min p = 3.97e-03)\n",
      "8. FARP2 (3 tests, min p = 5.50e-03)\n",
      "9. RUNDC3B (3 tests, min p = 5.51e-03)\n",
      "10. ZFAND3 (3 tests, min p = 5.56e-03)\n",
      "... and 156 more genes.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 05 Variant Extraction\n",
    "- Extract significant loci from VCF using bcftools\n",
    "- Apply allele frequency filters for rare variant validation\n",
    "- Generate RSID lists for candidate genes"
   ],
   "id": "2ea0031132a8fef4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# find variants in CDCA7L 7:21907041-21952042\n",
    "\n",
    "bcftools view -r 7:21907041-21952042 \"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/02_annotations/inputs/vcf/ADNI2_AD_CN_converted.vcf.gz\" \\\n",
    "  | bcftools view -i 'AF >0.005 && AF <=0.01' \\\n",
    "  > \"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/04_post_analysis/CDCA7L_ADNI_rare.vcf\"\n"
   ],
   "id": "ff525c3c4396716a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 03_post_analysis\n",
    "# ii. extract variants from significant regions with bcftools\n",
    "\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "# Input files (comment out unused to select input)\n",
    "SIGNIFICANT_GENES_FILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/04_post_analysis/multi_test_significant_genes.csv\"\n",
    "# SIGNIFICANT_GENES_FILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/04_post_analysis/significant_results.csv\"\n",
    "# SIGNIFICANT_GENES_FILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/04_post_analysis/best_results_per_gene.csv\"\n",
    "\n",
    "# Input VCF file\n",
    "VCF_FILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/02_dataset_conversion/ADNI2_AD_CN_converted.vcf.gz\"\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/05_variant_extraction\"\n",
    "\n",
    "# Allele frequency filter (rare variants)\n",
    "MIN_AF=\"0.005\"\n",
    "MAX_AF=\"0.01\"\n",
    "\n",
    "# Additional bcftools filters\n",
    "ADDITIONAL_FILTERS=\"\"   # e.g. \"&& QUAL>20 && DP>10\"\n",
    "\n",
    "# Processing options\n",
    "MAX_GENES_TO_PROCESS=\"20\"   # Leave empty to run all genes\n",
    "SKIP_EXISTING_FILES=\"true\"  # Skip existing files if true, overwrite if false\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "# ── Console Colours ─────────────────────────────\n",
    "RED='\\033[0;31m'\n",
    "GREEN='\\033[0;32m'\n",
    "YELLOW='\\033[1;33m'\n",
    "BLUE='\\033[0;34m'\n",
    "NC='\\033[0m' # No Colour\n",
    "\n",
    "\n",
    "# ── Dependency check ─────────────────────────────\n",
    "check_dependencies() {\n",
    "    echo -e \"${BLUE}🔍 Checking dependencies...${NC}\"\n",
    "    if ! command -v bcftools &>/dev/null; then\n",
    "        echo -e \"${RED}❌ Error: bcftools not found. Please install bcftools.${NC}\"\n",
    "        exit 1\n",
    "    fi\n",
    "    if ! command -v awk &>/dev/null; then\n",
    "        echo -e \"${RED}❌ Error: awk not found. Please install awk.${NC}\"\n",
    "        exit 1\n",
    "    fi\n",
    "    echo -e \"${GREEN}✅ All dependencies present.${NC}\"\n",
    "}\n",
    "\n",
    "\n",
    "# ── Parse genomic range ─────────────────────────────\n",
    "parse_genomic_range() {\n",
    "    local range_string=\"$1\"\n",
    "    range_string=$(echo \"$range_string\" | sed 's/\"//g' | cut -d',' -f1)\n",
    "    if [[ $range_string =~ ^([^:]+):([0-9]+)-([0-9]+)$ ]]; then\n",
    "        CHROM=\"${BASH_REMATCH[1]}\"\n",
    "        START=\"${BASH_REMATCH[2]}\"\n",
    "        END=\"${BASH_REMATCH[3]}\"\n",
    "        return 0\n",
    "    else\n",
    "        return 1\n",
    "    fi\n",
    "}\n",
    "\n",
    "\n",
    "# ── Extract variants for a gene ─────────────────────────────\n",
    "extract_variants_for_gene() {\n",
    "    local gene_name=\"$1\"\n",
    "    local chrom=\"$2\"\n",
    "    local start=\"$3\"\n",
    "    local end=\"$4\"\n",
    "\n",
    "    local output_file=\"${OUTPUT_DIR}/${gene_name}_ADNI_rare.vcf\"\n",
    "    local rsid_file=\"${OUTPUT_DIR}/${gene_name}_ADNI_rare_rsids.txt\"\n",
    "\n",
    "    # Skip pre-existing files\n",
    "    if [[ \"$SKIP_EXISTING_FILES\" == \"true\" && -f \"$output_file\" ]]; then\n",
    "        echo -e \"${YELLOW}⚠️  Skipping $gene_name - file already exists${NC}\"\n",
    "        return 0\n",
    "    fi\n",
    "\n",
    "    local region=\"${chrom}:${start}-${end}\"\n",
    "    local af_filter=\"AF >${MIN_AF} && AF <=${MAX_AF}\"\n",
    "    local full_filter=\"$af_filter ${ADDITIONAL_FILTERS}\"\n",
    "\n",
    "    echo -e \"${BLUE}📂 Extracting: $gene_name ($region)...${NC}\"\n",
    "\n",
    "    # Run bcftools\n",
    "    if bcftools view -r \"$region\" \"$VCF_FILE\" | bcftools view -i \"$full_filter\" > \"$output_file\" 2>/dev/null; then\n",
    "        if [[ -f \"$output_file\" ]]; then\n",
    "            local file_size=$(stat -c%s \"$output_file\" 2>/dev/null || echo \"0\")\n",
    "            local variant_count=$(grep -v '^#' \"$output_file\" 2>/dev/null | wc -l || echo \"0\")\n",
    "\n",
    "            if [[ $variant_count -gt 0 ]]; then\n",
    "                echo -e \"${GREEN}✅ Success: $variant_count variants extracted (${file_size} bytes).${NC}\"\n",
    "                echo \"$gene_name,Success,$variant_count variants (${file_size} bytes),${gene_name}_ADNI_rare.vcf,$chrom,$start,$end\" >> \"$results_file\"\n",
    "\n",
    "                # 🔹 Extract RSIDs into a separate txt file\n",
    "                awk '!/^#/ {print $3}' \"$output_file\" | grep -v '^\\.$' > \"$rsid_file\"\n",
    "                rsid_count=$(wc -l < \"$rsid_file\")\n",
    "                echo -e \"${GREEN}📄 RSID list created: $rsid_file (${rsid_count} IDs)${NC}\"\n",
    "\n",
    "            else\n",
    "                echo -e \"${YELLOW}ℹ️  Success: No variants matched AF filter.${NC}\"\n",
    "                echo \"$gene_name,Success,No variants found,${gene_name}_ADNI_rare.vcf,$chrom,$start,$end\" >> \"$results_file\"\n",
    "            fi\n",
    "\n",
    "        else\n",
    "            echo -e \"${RED}❌ Failed: Output file not created.${NC}\"\n",
    "            echo \"$gene_name,Failed,Output file not created,N/A,$chrom,$start,$end\" >> \"$results_file\"\n",
    "        fi\n",
    "    else\n",
    "        echo -e \"${RED}❌ Failed: bcftools command failed.${NC}\"\n",
    "        echo \"$gene_name,Failed,bcftools error,N/A,$chrom,$start,$end\" >> \"$results_file\"\n",
    "    fi\n",
    "}\n",
    "\n",
    "\n",
    "# ── Main ─────────────────────────────\n",
    "main() {\n",
    "    echo \"================================================\"\n",
    "    echo \"GENE VARIANT EXTRACTION\"\n",
    "    echo \"================================================\"\n",
    "    echo \"Input genes: $SIGNIFICANT_GENES_FILE\"\n",
    "    echo \"VCF file:    $VCF_FILE\"\n",
    "    echo \"Output dir:  $OUTPUT_DIR\"\n",
    "    echo \"AF filter:   $MIN_AF < AF <= $MAX_AF\"\n",
    "    [[ -n \"$ADDITIONAL_FILTERS\" ]] && echo \"Extra filters: $ADDITIONAL_FILTERS\"\n",
    "    [[ -n \"$MAX_GENES_TO_PROCESS\" ]] && echo \"Gene cap: $MAX_GENES_TO_PROCESS\"\n",
    "    echo \"Skip existing files: $SKIP_EXISTING_FILES\"\n",
    "    echo \"================================================\"\n",
    "\n",
    "    # Check tools\n",
    "    check_dependencies\n",
    "\n",
    "    # Validate files\n",
    "    [[ ! -f \"$SIGNIFICANT_GENES_FILE\" ]] && echo -e \"${RED}❌ Error: Input CSV missing.${NC}\" && exit 1\n",
    "    [[ ! -f \"$VCF_FILE\" ]] && echo -e \"${RED}❌ Error: VCF missing.${NC}\" && exit 1\n",
    "\n",
    "    mkdir -p \"$OUTPUT_DIR\"\n",
    "\n",
    "    # Log file\n",
    "    results_file=\"$OUTPUT_DIR/variant_extraction_results.csv\"\n",
    "    echo \"Gene,Status,Message,Output_File,Chromosome,Start,End\" > \"$results_file\"\n",
    "\n",
    "    # Identify columns\n",
    "    header_line=$(head -n 1 \"$SIGNIFICANT_GENES_FILE\")\n",
    "    echo \"📑 CSV header: $header_line\"\n",
    "\n",
    "    gene_col=$(echo \"$header_line\" | tr ',' '\\n' | grep -n \"Gene\" | cut -d':' -f1)\n",
    "    range_col=$(echo \"$header_line\" | tr ',' '\\n' | grep -n \"RANGE\" | cut -d':' -f1)\n",
    "    [[ -z \"$gene_col\" || -z \"$range_col\" ]] && echo -e \"${RED}❌ Gene/RANGE columns not found.${NC}\" && exit 1\n",
    "    echo \"✅ Found Gene @ col $gene_col, RANGE @ col $range_col\"\n",
    "\n",
    "    local processed_count=0\n",
    "\n",
    "    # Process CSV\n",
    "    tail -n +2 \"$SIGNIFICANT_GENES_FILE\" | while IFS= read -r line; do\n",
    "        [[ -n \"$MAX_GENES_TO_PROCESS\" && $processed_count -ge $MAX_GENES_TO_PROCESS ]] && break\n",
    "        IFS=',' read -ra FIELDS <<< \"$line\"\n",
    "        local gene_name=$(echo \"${FIELDS[$((gene_col-1))]}\" | sed 's/\"//g')\n",
    "        local range_string=$(echo \"${FIELDS[$((range_col-1))]}\" | sed 's/\"//g')\n",
    "\n",
    "        echo -e \"\\n🔬 Processing gene $((processed_count+1)): $gene_name\"\n",
    "        echo \"   Range: $range_string\"\n",
    "\n",
    "        if parse_genomic_range \"$range_string\"; then\n",
    "            echo \"   Parsed: $CHROM:$START-$END\"\n",
    "            extract_variants_for_gene \"$gene_name\" \"$CHROM\" \"$START\" \"$END\"\n",
    "        else\n",
    "            echo -e \"${RED}❌ Failed: Invalid genomic range '${range_string}'${NC}\"\n",
    "            echo \"$gene_name,Failed,Invalid range,N/A,N/A,N/A,N/A\" >> \"$results_file\"\n",
    "        fi\n",
    "        ((processed_count++))\n",
    "    done\n",
    "\n",
    "    echo -e \"\\n🏁 Pipeline complete.\"\n",
    "}\n",
    "\n",
    "\n",
    "# ── Run ─────────────────────────────\n",
    "main \"$@\"\n"
   ],
   "id": "bf7088c27f0ef3d6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
