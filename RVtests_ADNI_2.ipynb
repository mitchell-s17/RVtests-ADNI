{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Rare Variant Association Analysis with RVtests (ADNI)\n",
    "\n",
    "This notebook provides a full workflow for rare variant burden testing in the ADNI dataset using PLINK data with RVtests.\n",
    "\n",
    "## Workflow Overview\n",
    "\n",
    "### 1. Data Preparation & QC\n",
    "- Perform PLINK-based QC for rare (MAF 0.005–0.01) and common variants\n",
    "- LD pruning and PCA generation for population structure control\n",
    "- Generate phenotype, covariate, and keep files for AD vs CN baseline samples\n",
    "\n",
    "### 2. Dataset Conversion\n",
    "- Filter rare variant dataset to matched samples\n",
    "- Convert PLINK binary files to VCF, followed by compression and indexing\n",
    "\n",
    "### 3. Association Testing (RVtests)\n",
    "- Gene-based rare variant testing using:\n",
    "  - CMC (burden test)\n",
    "  - SKAT-O (kernel test)\n",
    "  - Variable Threshold (Price)\n",
    "- Adjusts for covariates (age, sex, education, APOE4, PCs)\n",
    "\n",
    "### 4. Post-Analysis\n",
    "- Aggregate and compare results across tests\n",
    "- Identify genes significant in multiple methods\n",
    "- Export summary statistics and significant findings\n",
    "\n",
    "### 5. Variant Extraction\n",
    "- Extract significant loci from VCF using bcftools\n",
    "- Apply allele frequency filters for rare variant validation\n",
    "- Generate RSID lists for candidate genes\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Citations\n",
    "\n",
    "> Petersen RC, et al. Alzheimer's Disease Neuroimaging Initiative. Alzheimers Dement. 2010 May;6(3):238-46. </p>\n",
    "> Xiaowei Zhan, et al. RVTESTS: An Efficient and Comprehensive Tool for Rare Variant Association Analysis Using Sequence Data. Bioinformatics. 2016 32: 1423-1426."
   ],
   "id": "8da654eba73d2b56"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 01 Data prepartion & QC\n",
    "i. PLINK QC for rare variants <br>\n",
    "ii. PLINK QC for common variants <br>\n",
    "iii. LD pruning <br>\n",
    "iv. PCA <br>\n",
    "v. Pheno & covar file creation <br>"
   ],
   "id": "f8ab22490f01f150"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 01_data_prep_qc\n",
    "# i. PLINK QC for rare variants\n",
    "\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "BFILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/01_data_prep_qc/inputs/ADNI_merged\"\n",
    "OUTPUT=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/01_data_prep_qc/outputs/rare_plink/ADNI2_rare\"\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "\n",
    "# ── QC rare variants ─────────────────────────────\n",
    "\n",
    "plink --bfile \"${BFILE}\" \\\n",
    "      --maf 0.005 \\\n",
    "      --max-maf 0.01 \\\n",
    "      --geno 0.05 \\\n",
    "      --mind 0.05 \\\n",
    "      --hwe 1e-6 \\\n",
    "      --mac 1 \\\n",
    "      --not-chr 0,M \\\n",
    "      --output-chr M \\\n",
    "      --make-bed \\\n",
    "      --out \"${OUTPUT}\"\n",
    "STATUS=$?\n",
    "\n",
    "if [ $STATUS -ne 0 ]; then\n",
    "  echo \"❌ ERROR: PLINK QC failed with exit code $STATUS\"\n",
    "  exit $STATUS\n",
    "fi\n",
    "\n",
    "echo \"✅ Files saved: ${OUTPUT}.[bed|bim|fam]\"\n",
    "echo \"🏁 QC (rare) complete.\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 01_data_prep_qc\n",
    "# ii. PLINK QC for common variants\n",
    "\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "BFILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/01_data_prep_qc/inputs/ADNI_merged\"\n",
    "OUTPUT=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/01_data_prep_qc/outputs/common_plink/ADNI2_common\"\n",
    "\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "\n",
    "# ── QC common variants ─────────────────────────────\n",
    "\n",
    "plink --bfile \"$BFILE\" \\\n",
    "      --maf 0.01 \\\n",
    "      --geno 0.05 \\\n",
    "      --mind 0.05 \\\n",
    "      --hwe 1e-6 \\\n",
    "      --mac 1 \\\n",
    "      --not-chr 0,M \\\n",
    "      --output-chr M \\\n",
    "      --make-bed \\\n",
    "      --out \"$OUTPUT\"\n",
    "STATUS=$?\n",
    "\n",
    "if [ $STATUS -ne 0 ]; then\n",
    "  echo \"❌ ERROR: PLINK QC failed with exit code $STATUS\"\n",
    "  exit $STATUS\n",
    "fi\n",
    "\n",
    "echo \"✅ Files saved: ${OUTPUT}.[bed|bim|fam]\"\n",
    "echo \"🏁 QC (common) complete.\""
   ],
   "id": "97e5eac48ea734c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 01_data_prep_qc\n",
    "# iii. LD pruning\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "BFILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/01_data_prep_qc/outputs/common_plink/ADNI2_common\"\n",
    "\n",
    "OUTPUT=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/01_data_prep_qc/outputs/LD_pruning/ADNI2_pruned\"\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "\n",
    "# ── LD pruning ─────────────────────────────\n",
    "\n",
    "plink \\\n",
    "  --bfile \"$BFILE\" \\\n",
    "  --indep-pairwise 200 50 0.3 \\\n",
    "  --out \"$OUTPUT\"\n",
    "STATUS=$?\n",
    "\n",
    "if [ $STATUS -ne 0 ]; then\n",
    "  echo \"❌ ERROR: PLINK QC failed with exit code $STATUS\"\n",
    "  exit $STATUS\n",
    "fi\n",
    "\n",
    "echo \"✅ Files saved: ${OUTPUT}\"\n",
    "echo \"🏁 LD pruning complete."
   ],
   "id": "8187b162e6009fe7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 01_data_prep_qc\n",
    "# iv. PCA generation on common variants set\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "BFILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/01_data_prep_qc/outputs/common_plink/ADNI2_common\"\n",
    "\n",
    "PRUNED=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/01_data_prep_qc/outputs/LD_pruning/ADNI2_pruned.prune.in\"\n",
    "\n",
    "OUTPUT=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/01_data_prep_qc/outputs/PCA/ADNI2_PCA\"\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "# ── PCA generation ─────────────────────────────\n",
    "\n",
    "plink \\\n",
    "  --bfile \"$BFILE\" \\\n",
    "  --extract \"$PRUNED\" \\\n",
    "  --pca 10 header \\\n",
    "  --out \"$OUTPUT\"\n",
    "STATUS=$?\n",
    "\n",
    "if [ $STATUS -ne 0 ]; then\n",
    "  echo \"❌ ERROR: PLINK QC failed with exit code $STATUS\"\n",
    "  exit $STATUS\n",
    "fi\n",
    "\n",
    "echo \"✅ Files saved: ${OUTPUT}\"\n",
    "echo \"🏁 PCA complete.\"\n"
   ],
   "id": "6cfb41b276cf899b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 01_data_prep_qc\n",
    "# v. Generate pheno and covar files\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "ADNI_MERGE_PATH = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\5. Rvtests\\01_data_prep_qc\\inputs\\ADNIMERGE_15May2025.csv\"\n",
    "PLINK_FAM_PATH  = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\5. Rvtests\\01_data_prep_qc\\outputs\\rare_plink\\ADNI2_rare.fam\"\n",
    "\n",
    "PCA_FILE = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\5. Rvtests\\01_data_prep_qc\\outputs\\PCA\\ADNI2_PCA.eigenvec\"\n",
    "\n",
    "OUTPUT_DIR = Path(r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\5. Rvtests\\01_data_prep_qc\\outputs\\pheno_covar\")\n",
    "\n",
    "NUM_PCS = 10  # Number of principal components to merge\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "# ── Load data  ─────────────────────────────\n",
    "\n",
    "def load_pca_data(pca_path, num_pcs):\n",
    "    print(f\"📖 Loading PCA data with {num_pcs} components...\")\n",
    "    pca_columns = [\"fid\", \"iid\"] + [f\"PC{i}\" for i in range(1, num_pcs + 1)]\n",
    "    pca = pd.read_csv(pca_path, sep=r'\\s+', header=0, names=pca_columns, dtype={\"fid\": str, \"iid\": str})\n",
    "    print(f\"✅ Loaded PCA data for {len(pca)} samples\")\n",
    "    return pca\n",
    "\n",
    "def save_keep_list(pheno_df, outdir):\n",
    "    keep_path = outdir / \"ADNI_AD_vs_CN.keep\"\n",
    "    pheno_df[['fid', 'iid']].to_csv(keep_path, sep='\\t', index=False, header=False)\n",
    "    print(f\"📄 Keep-list saved: {keep_path}\")\n",
    "    return keep_path\n",
    "\n",
    "def main():\n",
    "    print(\"📥 Loading ADNI phenotype and PLINK sample data...\")\n",
    "    adni_data = pd.read_csv(ADNI_MERGE_PATH, low_memory=False)\n",
    "    plink_fam = pd.read_csv(\n",
    "        PLINK_FAM_PATH, sep=r'\\s+', header=None,\n",
    "        names=['fid', 'iid', 'PAT', 'MAT', 'SEX', 'PHENOTYPE']\n",
    "    )\n",
    "\n",
    "    # ── Filter AD vs CN ─────────────────────────────\n",
    "    ad_cn_data = adni_data[(adni_data['VISCODE'] == 'bl') & (adni_data['DX_bl'].isin(['AD', 'CN']))].copy()\n",
    "    print(f\"🔍 Baseline AD vs CN: {len(ad_cn_data)} samples (before matching)\")\n",
    "\n",
    "    # ── Match PTIS and IIDM map FID ─────────────────────────────\n",
    "    ad_cn_data['iid'] = ad_cn_data['PTID'].astype(str)\n",
    "    ad_cn_data = ad_cn_data[ad_cn_data['iid'].isin(plink_fam['iid'].astype(str))]\n",
    "    iid_to_fid = dict(zip(plink_fam['iid'].astype(str), plink_fam['fid']))\n",
    "    ad_cn_data['fid'] = ad_cn_data['iid'].map(iid_to_fid)\n",
    "\n",
    "    if ad_cn_data['fid'].isnull().any():\n",
    "        missing = ad_cn_data[ad_cn_data['fid'].isnull()]['iid'].tolist()\n",
    "        print(\"⚠️ WARNING: Some samples could not be mapped to FIDs\")\n",
    "        print(f\"Missing FID for: {missing}\")\n",
    "\n",
    "    print(f\"✅ After genetic match: {len(ad_cn_data)} samples => \"\n",
    "          f\"{(ad_cn_data['DX_bl']=='AD').sum()} AD, {(ad_cn_data['DX_bl']=='CN').sum()} CN\")\n",
    "\n",
    "    # ── create phenotypes and covariates ─────────────────────────────\n",
    "    ad_cn_data['sex'] = ad_cn_data['PTGENDER'].map({'Male': 1, 'Female': 0})\n",
    "    ad_cn_data['age'] = ad_cn_data['AGE']\n",
    "    ad_cn_data['education'] = ad_cn_data['PTEDUCAT']\n",
    "    ad_cn_data['apoe4_count'] = ad_cn_data['APOE4']\n",
    "\n",
    "    phenotype_cols = ['fid', 'iid', 'DX_bl', 'age', 'sex', 'education', 'apoe4_count', 'PTID']\n",
    "    pheno_df = ad_cn_data[phenotype_cols].dropna(subset=['DX_bl', 'age', 'sex', 'education', 'apoe4_count'])\n",
    "    print(f\"🔍 Final sample size: {len(pheno_df)} \"\n",
    "          f\"({(pheno_df['DX_bl']=='AD').sum()} AD, {(pheno_df['DX_bl']=='CN').sum()} CN)\")\n",
    "\n",
    "    # ── merge with parentals IDs and numeric sex from FAM ─────────────────────────────\n",
    "    fam_cols = plink_fam[['fid', 'iid', 'PAT', 'MAT', 'SEX']].copy()\n",
    "    fam_cols.rename(columns={'PAT': 'fatid', 'MAT': 'matid', 'SEX': 'sex_fam'}, inplace=True)\n",
    "\n",
    "\n",
    "# ── PHENOTYPE FILE GENERATION (y1 = AD vs CN) ─────────────────────────────\n",
    "\n",
    "    pheno_merged = pd.merge(pheno_df, fam_cols, on=['fid', 'iid'], how='left')\n",
    "    pheno_merged['DX_bl'] = pheno_merged['DX_bl'].str.strip().str.upper()\n",
    "    pheno_merged['y1'] = pheno_merged['DX_bl'].map({'CN': 1, 'AD': 2}).astype('Int64')\n",
    "\n",
    "    pheno_final = pheno_merged[['fid', 'iid', 'fatid', 'matid', 'sex_fam', 'y1']].copy()\n",
    "    pheno_final.rename(columns={'sex_fam': 'sex'}, inplace=True)\n",
    "    pheno_final.to_csv(\n",
    "        OUTPUT_DIR / \"ADNI_AD_vs_CN.pheno\",\n",
    "        sep='\\t', index=False, na_rep='NA'\n",
    "    )\n",
    "\n",
    "\n",
    "# ── COVARIATE FILE GENERATION (covars + PCs, no duplicate sex) ─────────────────────────────\n",
    "\n",
    "    covar_base = pheno_df[['fid', 'iid', 'age', 'education', 'apoe4_count']].copy()\n",
    "    covar_merged = pd.merge(covar_base, fam_cols, on=['fid', 'iid'], how='left')\n",
    "\n",
    "    # Load PCA data\n",
    "    pca_df = load_pca_data(PCA_FILE, NUM_PCS)\n",
    "\n",
    "    # Merge covariates + PCA\n",
    "    covar_with_pcs = pd.merge(covar_merged, pca_df.drop(columns='fid'), on='iid', how='left')\n",
    "\n",
    "    # Reorder: fid iid fatid matid sex age education apoe4_count PC1...PCn\n",
    "    covar_final = covar_with_pcs[['fid', 'iid', 'fatid', 'matid', 'sex_fam',\n",
    "                                  'age', 'education', 'apoe4_count'] +\n",
    "                                 [f\"PC{i}\" for i in range(1, NUM_PCS + 1)]].copy()\n",
    "    covar_final.rename(columns={'sex_fam': 'sex'}, inplace=True)\n",
    "\n",
    "    covar_final.to_csv(\n",
    "        OUTPUT_DIR / \"ADNI_AD_vs_CN.covar\",\n",
    "        sep='\\t', index=False, na_rep='NA'\n",
    "    )\n",
    "\n",
    "    # Save keep-list file for PLINK\n",
    "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    keep_path = save_keep_list(pheno_df, OUTPUT_DIR)\n",
    "\n",
    "    # Save summary and stats\n",
    "    pheno_df.to_csv(\n",
    "        OUTPUT_DIR / \"ADNI_AD_vs_CN_summary.txt\",\n",
    "        sep='\\t', index=False, na_rep='NA'\n",
    "    )\n",
    "\n",
    "    summary_stats = pheno_df.groupby('DX_bl').agg({\n",
    "        'age': ['count', 'mean', 'std'],\n",
    "        'sex': 'mean',\n",
    "        'education': ['mean', 'std'],\n",
    "        'apoe4_count': ['mean', 'std']\n",
    "    }).round(2)\n",
    "\n",
    "    summary_stats.to_csv(\n",
    "        OUTPUT_DIR / \"ADNI_AD_vs_CN_summary_stats.txt\",\n",
    "        sep='\\t'\n",
    "    )\n",
    "\n",
    "    print(f\"\\n✅ Files saved to: {OUTPUT_DIR}\")\n",
    "    print(f\"✅ Phenotype file: {OUTPUT_DIR / 'ADNI_AD_vs_CN.pheno'}\")\n",
    "    print(f\"✅ Covariate file: {OUTPUT_DIR / 'ADNI_AD_vs_CN.covar'}\")\n",
    "    print(f\"🏁 Processing complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "697245036fb5eef3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 02 Dataset conversion\n",
    "i. Filter rare variant dataset to matched samples <br>\n",
    "ii. Convert to VCF (compression and indexing) <br>\n",
    "iii. Annotation (create annotated vcf to filer by variants)"
   ],
   "id": "4b325c8fff19715"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 02_dataset_conversion\n",
    "# i. filter plink rare to keep only samples with pheno data\n",
    "\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "BFILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/01_data_prep_qc/outputs/rare_plink/ADNI2_rare\"\n",
    "OUTPUT=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/02_dataset_conversion/ADNI2_AD_CN\"\n",
    "KEEP=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/01_data_prep_qc/outputs/pheno_covar/ADNI_AD_vs_CN.keep\"\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "\n",
    "# ── QC rare variants ─────────────────────────────\n",
    "\n",
    "plink --bfile \"$BFILE\" \\\n",
    "      --keep \"$KEEP\" \\\n",
    "      --make-bed \\\n",
    "      --out \"$OUTPUT\"\n",
    "STATUS=$?\n",
    "\n",
    "if [ $STATUS -ne 0 ]; then\n",
    "  echo \"❌ ERROR: PLINK QC failed with exit code $STATUS\"\n",
    "  exit $STATUS\n",
    "fi\n",
    "\n",
    "echo \"✅ Files saved: ${OUTPUT}.[bed|bim|fam]\"\n",
    "echo \"🏁 complete.\""
   ],
   "id": "6a7901ad34649917",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 02_dataset_conversion\n",
    "# ii. convert to compressed vcf + index\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "INPUT=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/02_dataset_conversion/ADNI2_AD_CN\"\n",
    "\n",
    "OUTPUT=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/02_dataset_conversion/ADNI2_AD_CN_converted\"\n",
    "\n",
    "VCF=\"${OUTPUT}.vcf\"\n",
    "\n",
    "BGZ=\"${VCF}.gz\"\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "# ── convert to vcf & compress + index ─────────────────────────────\n",
    "\n",
    "plink \\\n",
    "    --bfile \"${INPUT}\" \\\n",
    "    --recode vcf-iid \\\n",
    "    --out \"${OUTPUT}\"\n",
    "\n",
    "bgzip -f \"${VCF}\"\n",
    "tabix -p vcf \"${BGZ}\"\n",
    "\n",
    "echo \"✅ Files saved: ${BGZ} and ${BGZ}.tbi\"\n",
    "echo \"🏁 VCF conversion, compression, and indexing complete\"\n"
   ],
   "id": "f5117d9d6beaad2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 02_dataset_conversion [optional]\n",
    "# iii. produce annotated vcf file to filter variants on expression\n",
    "\n",
    "cd anno\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "INPUT_VCF=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/02_dataset_conversion/ADNI2_AD_CN_converted.vcf.gz\"\n",
    "OUTPUT_VCF=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/02_dataset_conversion/annotation/ADNI2_AD_CN_anno.vcf.gz\"\n",
    "REFERENCE_FA=\"/home/swmitchell/anno/resources/hs37d5.fa\"\n",
    "GENE_ANNOTATION=\"/home/swmitchell/anno/resources/refFlat_hg19.txt.gz\"\n",
    "PRIORITY_FILE=\"/home/swmitchell/anno/resources/priority.txt\"\n",
    "CODON_FILE=\"/home/swmitchell/anno/resources/codon.txt\"\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "./executable/anno \\\n",
    "  -i \"$INPUT_VCF\" \\\n",
    "  -o \"$OUTPUT_VCF\" \\\n",
    "  -r \"$REFERENCE_FA\" \\\n",
    "  -g \"$GENE_ANNOTATION\" \\\n",
    "  -p \"$PRIORITY_FILE\" \\\n",
    "  -c \"$CODON_FILE\" \\\n",
    "  --indexOutput"
   ],
   "id": "9943743b8daa45f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 03 Association Testing (RVtests)\n",
    "i. Gene-based rare variant testing using:\n",
    "  - CMC (burden test)\n",
    "  - SKAT-O (kernel test)\n",
    "  - Variable Threshold (Price)"
   ],
   "id": "46449d8013000deb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#rvtest\n",
    "\n",
    "#groupwise tests\n",
    "# example\n",
    "\n",
    "rvtest --inVcf rarevariants.vcf.gz \\\n",
    "   --pheno pheno.ped \\\n",
    "   --out output \\\n",
    "   --geneFile refFlat_hg19.txt.gz \\ # to specify the gene range in a refFlat format\n",
    "   --burden cmc \\ # collapsing and combine rare variants\n",
    "   --vt price \\\n",
    "   --kernel skato \\\n",
    "   --covar example.covar \\\n",
    "   --covar-name age,sex,education,apoe4_count,PC1,PC2,PC3,PC4,PC5,PC6,PC7,PC8,PC9,PC10 \\\n",
    "   --freqUpper 0.01 \\ # Specify upper minor allele frequency bound to be included in analysis\n",
    "   --freqLower 0.001 \\ # Specify lower minor allele frequency bound to be included in analysis\n"
   ],
   "id": "103860d3cc80432",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 03_rvtests\n",
    "# i. run Rvtests\n",
    "\n",
    "cd rvtests\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "# use normal vcf for non-annotation run\n",
    "INVCF=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/02_dataset_conversion/ADNI2_AD_CN_converted.vcf.gz\"\n",
    "\n",
    "# if filtering based on annotation, need annotated vcf\n",
    "#INVCF=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/02_dataset_conversion/annotation/ADNI2_AD_CN_anno.vcf.gz\"\n",
    "\n",
    "PHENO=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/01_data_prep_qc/outputs/pheno_covar/ADNI_AD_vs_CN.pheno\"\n",
    "\n",
    "COVAR=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/01_data_prep_qc/outputs/pheno_covar/ADNI_AD_vs_CN.covar\"\n",
    "\n",
    "GENEFILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/03_rvtests/inputs/refFlat.txt.gz\"\n",
    "\n",
    "OUTDIR=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/03_rvtests/outputs\"\n",
    "\n",
    "OUTFILE=\"${OUTDIR}/ADNI2_rvtest\"\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "# ── run rvtests ─────────────────────────────\n",
    "\n",
    "./executable/rvtest \\\n",
    "  --inVcf \"$INVCF\" \\\n",
    "  --pheno \"$PHENO\" \\\n",
    "  --out \"$OUTFILE\" \\\n",
    "  --geneFile \"$GENEFILE\" \\\n",
    "  --burden cmc \\\n",
    "  --vt price \\\n",
    "  --kernel skato \\\n",
    "  --covar \"$COVAR\" \\\n",
    "  --covar-name age,sex,education,apoe4_count,PC1,PC2,PC3,PC4,PC5,PC6,PC7,PC8,PC9,PC10 \\\n",
    "  --freqUpper 0.01 \\\n",
    "  --freqLower 0.005 \\\n",
    "  --noweb \\\n",
    " # --annoType Start_Gain|Stop_Loss|Start_Loss|Essential_Splice_Site|Stop_Gain|Normal_Splice_Site|Synonymous|Nonsynonymous \\ #filter variants based on annotation\n",
    "  --outputRaw\n",
    "\n"
   ],
   "id": "9532e19b3982fed4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 04 Post-Analysis\n",
    "- Aggregate and compare results across tests\n",
    "- Identify genes significant in multiple methods\n",
    "- Export summary statistics and significant findings\n"
   ],
   "id": "7c64d579e68d6ec5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 04_post_analysis\n",
    "# Processes CMC, SKAT-O, and Variable Threshold Price test results,\n",
    "# Applies multiple testing corrections and identifies significant genes for further investigation.\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from scipy import stats\n",
    "import statsmodels.stats.multitest as smm\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "# Input file paths\n",
    "CMC_FILE = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\5. Rvtests\\03_rvtests\\outputs\\ADNI2_rvtest.CMC.assoc\"\n",
    "SKATO_FILE = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\5. Rvtests\\03_rvtests\\outputs\\ADNI2_rvtest.SkatO.assoc\"\n",
    "VT_FILE = r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\5. Rvtests\\03_rvtests\\outputs\\ADNI2_rvtest.VariableThresholdPrice.assoc\"\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = Path(r\"C:\\Users\\B00731414\\OneDrive - Ulster University\\6. Code\\ADNI\\5. Rvtests\\04_post_analysis\")\n",
    "\n",
    "# Significance thresholds\n",
    "HIGHLY_SIGNIFICANT_THRESHOLD = 0.001\n",
    "SIGNIFICANT_THRESHOLD = 0.01\n",
    "SUGGESTIVE_THRESHOLD = 0.05\n",
    "PRIMARY_THRESHOLD = 0.05  # Primary reporting threshold\n",
    "\n",
    "# Display settings\n",
    "TOP_RESULTS_TO_SHOW = 20\n",
    "MAX_GENES_TO_LIST = 10\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "\n",
    "# ── Multiple testing corrections ─────────────────────────────\n",
    "\n",
    "# Apply multiple testing corrections to p-values.\n",
    "# return df with add cols for corrected p-values\n",
    "\n",
    "def apply_multiple_testing_correction(df, p_column='P_value', methods=['bonferroni', 'fdr_bh']):\n",
    "    df = df.copy()\n",
    "    valid_pvals = df[p_column].notna() & (df[p_column] > 0)\n",
    "    for method in methods:\n",
    "        if method == 'bonferroni':\n",
    "            # Bonferroni correction\n",
    "            n_tests = valid_pvals.sum()\n",
    "            df['p_bonferroni'] = df[p_column] * n_tests\n",
    "            df['p_bonferroni'] = df['p_bonferroni'].clip(upper=1.0)  # Cap at 1.0\n",
    "            df['sig_bonferroni'] = df['p_bonferroni'] < 0.05\n",
    "        elif method == 'fdr_bh':\n",
    "            # Benjamini-Hochberg FDR correction\n",
    "            pvals = df[p_column][valid_pvals].values\n",
    "            rejected, p_corrected, _, _ = smm.multipletests(pvals, method='fdr_bh', alpha=0.05)\n",
    "            # Create full arrays with NaN for missing values\n",
    "            df['p_fdr_bh'] = np.nan\n",
    "            df['sig_fdr_bh'] = False\n",
    "            df.loc[valid_pvals, 'p_fdr_bh'] = p_corrected\n",
    "            df.loc[valid_pvals, 'sig_fdr_bh'] = rejected\n",
    "    return df\n",
    "\n",
    "# calculate sig thresholds for Bonf / FDR\n",
    "def calculate_significance_thresholds(n_tests):\n",
    "    bonferroni_threshold = 0.05 / n_tests\n",
    "    print(f\"\\nSignificance Thresholds:\")\n",
    "    print(f\"Nominal p < 0.05\")\n",
    "    print(f\"Bonferroni p < {bonferroni_threshold:.2e} (0.05/{n_tests})\")\n",
    "    print(f\"FDR q < 0.05 (adaptive threshold)\")\n",
    "    return {\n",
    "        'nominal': 0.05,\n",
    "        'bonferroni': bonferroni_threshold,\n",
    "        'fdr': 0.05  # q-value threshold\n",
    "    }\n",
    "\n",
    "# ── Correction reporting ─────────────────────────────\n",
    "def generate_correction_summary_report(best_results_corrected, output_dir):\n",
    "    summary_stats = {\n",
    "        'Total_Genes': len(best_results_corrected),\n",
    "        'Nominal_Significant': (best_results_corrected['P_value'] < 0.05).sum(),\n",
    "        'Bonferroni_Significant': (best_results_corrected['p_bonferroni'] < 0.05).sum(),\n",
    "        'FDR_Significant': (best_results_corrected['sig_fdr_bh']).sum(),\n",
    "        'Bonferroni_Threshold': f\"{0.05/len(best_results_corrected):.2e}\",\n",
    "    }\n",
    "    # Save summary\n",
    "    summary_df = pd.DataFrame([summary_stats])\n",
    "    summary_df.to_csv(output_dir / \"multiple_testing_summary.csv\", index=False)\n",
    "    # save lists of significant genes by different criteria\n",
    "    if summary_stats['FDR_Significant'] > 0:\n",
    "        fdr_genes = best_results_corrected[best_results_corrected['sig_fdr_bh']]['Gene'].tolist()\n",
    "        pd.DataFrame({'Gene': fdr_genes}).to_csv(output_dir / \"FDR_significant_genes.csv\", index=False)\n",
    "    if summary_stats['Bonferroni_Significant'] > 0:\n",
    "        bonf_genes = best_results_corrected[best_results_corrected['sig_bonferroni']]['Gene'].tolist()\n",
    "        pd.DataFrame({'Gene': bonf_genes}).to_csv(output_dir / \"Bonferroni_significant_genes.csv\", index=False)\n",
    "    return summary_stats\n",
    "\n",
    "# ── Load and process Rvtests results ─────────────────────────────\n",
    "\n",
    "def load_and_process_files(cmc_file, skato_file, vt_file):\n",
    "    results = {}\n",
    "    try:\n",
    "        cmc_df = pd.read_csv(cmc_file, sep='\\t')\n",
    "        cmc_df['Test_Type'] = 'CMC'\n",
    "        cmc_df['P_value'] = cmc_df['Pvalue']\n",
    "        results['CMC'] = cmc_df\n",
    "        print(f\"📂 Loaded CMC file: {len(cmc_df)} genes\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading CMC file: {e}\")\n",
    "        return None\n",
    "    try:\n",
    "        skato_df = pd.read_csv(skato_file, sep='\\t')\n",
    "        skato_df['Test_Type'] = 'SKAT-O'\n",
    "        skato_df['P_value'] = skato_df['Pvalue']\n",
    "        results['SKAT-O'] = skato_df\n",
    "        print(f\"📂 Loaded SKAT-O file: {len(skato_df)} genes\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading SKAT-O file: {e}\")\n",
    "        return None\n",
    "    try:\n",
    "        vt_df = pd.read_csv(vt_file, sep='\\t')\n",
    "        vt_df['Test_Type'] = 'Variable_Threshold'\n",
    "        vt_df['P_value'] = vt_df['PermPvalue']\n",
    "        results['Variable_Threshold'] = vt_df\n",
    "        print(f\"📂 Loaded Variable Threshold file: {len(vt_df)} genes\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading Variable Threshold file: {e}\")\n",
    "        return None\n",
    "    return results\n",
    "\n",
    "# ── Significance metrics ─────────────────────────────\n",
    "# Calculate -log10(p) values and assign defined sig categories\n",
    "\n",
    "def calculate_significance_metrics(df, p_col='P_value'):\n",
    "    df = df.copy()\n",
    "    df['neg_log10_p'] = -np.log10(df[p_col].replace(0, 1e-300))  # handle p=0\n",
    "    df['significance_level'] = pd.cut(\n",
    "        df[p_col],\n",
    "        bins=[0, HIGHLY_SIGNIFICANT_THRESHOLD, SIGNIFICANT_THRESHOLD, SUGGESTIVE_THRESHOLD, 1.0],\n",
    "        labels=['Highly_Significant', 'Significant', 'Suggestive', 'Not_Significant'],\n",
    "        include_lowest=True\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# ── Merge results ─────────────────────────────\n",
    "def merge_results(results_dict):\n",
    "    merged_results = []\n",
    "    for test_type, df in results_dict.items():\n",
    "        if test_type == 'CMC':\n",
    "            cols = ['Gene', 'RANGE', 'N_INFORMATIVE', 'NumVar', 'NumPolyVar',\n",
    "                    'NonRefSite', 'P_value', 'Test_Type', 'neg_log10_p', 'significance_level']\n",
    "        elif test_type == 'SKAT-O':\n",
    "            cols = ['Gene', 'RANGE', 'N_INFORMATIVE', 'NumVar', 'NumPolyVar',\n",
    "                    'Q', 'rho', 'P_value', 'Test_Type', 'neg_log10_p', 'significance_level']\n",
    "        else:  # Variable Threshold\n",
    "            cols = ['Gene', 'RANGE', 'N_INFORMATIVE', 'NumVar', 'NumPolyVar',\n",
    "                    'OptFreq', 'Zmax', 'Stat', 'P_value', 'Test_Type', 'neg_log10_p', 'significance_level']\n",
    "        available_cols = [col for col in cols if col in df.columns]\n",
    "        merged_results.append(df[available_cols])\n",
    "    combined_df = pd.concat(merged_results, ignore_index=True, sort=False)\n",
    "    return combined_df\n",
    "\n",
    "# ── Gene-level aggregation ─────────────────────────────\n",
    "# select best result per gene\n",
    "def find_best_result_per_gene(combined_df):\n",
    "    best_results = combined_df.loc[combined_df.groupby('Gene')['P_value'].idxmin()].copy()\n",
    "    return best_results.sort_values('P_value')\n",
    "\n",
    "# ── Cross-test significance ─────────────────────────────\n",
    "# get cross-test sig for each gene\n",
    "def analyze_cross_test_significance(combined_df, threshold=PRIMARY_THRESHOLD):\n",
    "    gene_test_matrix = combined_df.pivot(index='Gene', columns='Test_Type', values='P_value')\n",
    "    significant_counts = (gene_test_matrix < threshold).sum(axis=1)\n",
    "    all_tests_sig = significant_counts[significant_counts == 3].index.tolist()\n",
    "    two_tests_sig = significant_counts[significant_counts == 2].index.tolist()\n",
    "    one_test_sig = significant_counts[significant_counts == 1].index.tolist()\n",
    "    cross_test_results = []\n",
    "    for gene in combined_df['Gene'].unique():\n",
    "        gene_data = combined_df[combined_df['Gene'] == gene]\n",
    "        result = {'Gene': gene}\n",
    "        if 'RANGE' in gene_data: result['RANGE'] = gene_data['RANGE'].iloc[0]\n",
    "        if 'N_INFORMATIVE' in gene_data: result['N_INFORMATIVE'] = gene_data['N_INFORMATIVE'].iloc[0]\n",
    "        if 'NumVar' in gene_data: result['NumVar'] = gene_data['NumVar'].iloc[0]\n",
    "        if 'NumPolyVar' in gene_data: result['NumPolyVar'] = gene_data['NumPolyVar'].iloc[0]\n",
    "        for test_type in ['CMC', 'SKAT-O', 'Variable_Threshold']:\n",
    "            test_data = gene_data[gene_data['Test_Type'] == test_type]\n",
    "            if len(test_data) > 0:\n",
    "                p_val = test_data['P_value'].iloc[0]\n",
    "                result[f'{test_type}_pval'] = p_val\n",
    "                result[f'{test_type}_sig'] = 'Yes' if p_val < threshold else 'No'\n",
    "            else:\n",
    "                result[f'{test_type}_pval'] = np.nan\n",
    "                result[f'{test_type}_sig'] = 'N/A'\n",
    "        result['Tests_Significant'] = sum([1 for test in ['CMC', 'SKAT-O', 'Variable_Threshold']\n",
    "                                           if result[f'{test}_sig'] == 'Yes'])\n",
    "        result['Min_Pvalue'] = min([result[f'{test}_pval']\n",
    "                                    for test in ['CMC', 'SKAT-O', 'Variable_Threshold']\n",
    "                                    if not pd.isna(result[f'{test}_pval'])])\n",
    "        cross_test_results.append(result)\n",
    "    cross_test_df = pd.DataFrame(cross_test_results)\n",
    "    cross_test_df = cross_test_df.sort_values(['Tests_Significant', 'Min_Pvalue'], ascending=[False, True])\n",
    "    return cross_test_df, all_tests_sig, two_tests_sig, one_test_sig\n",
    "\n",
    "# ── Reporting ─────────────────────────────\n",
    "def generate_summary_report(results_dict, combined_df, best_results, cross_test_df,\n",
    "                            all_tests_sig, two_tests_sig, one_test_sig):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RARE VARIANT TESTING RESULTS SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Significance thresholds:\")\n",
    "    print(f\"  - Highly significant: p < {HIGHLY_SIGNIFICANT_THRESHOLD}\")\n",
    "    print(f\"  - Significant: p < {SIGNIFICANT_THRESHOLD}\")\n",
    "    print(f\"  - Suggestive: p < {SUGGESTIVE_THRESHOLD}\")\n",
    "    print(f\"  - Primary threshold: p < {PRIMARY_THRESHOLD}\")\n",
    "    print(f\"\\n🔍 Overall statistics:\")\n",
    "    print(f\"Total unique genes analysed: {len(combined_df['Gene'].unique())}\")\n",
    "    print(f\"Total test results processed: {len(combined_df)}\")\n",
    "    print(f\"\\n🧪 Results by test type:\")\n",
    "    for test_type in ['CMC', 'SKAT-O', 'Variable_Threshold']:\n",
    "        test_df = combined_df[combined_df['Test_Type'] == test_type]\n",
    "        sig_count = len(test_df[test_df['P_value'] < PRIMARY_THRESHOLD])\n",
    "        print(f\" - {test_type}: {len(test_df)} genes, {sig_count} significant\")\n",
    "    print(f\"\\n📊 Cross-test significance analysis:\")\n",
    "    print(f\"Genes significant in all 3 tests: {len(all_tests_sig)}\")\n",
    "    print(f\"Genes significant in 2 tests: {len(two_tests_sig)}\")\n",
    "    print(f\"Genes significant in 1 test: {len(one_test_sig)}\")\n",
    "    print(f\"\\n📌 Significance summary (best result per gene):\")\n",
    "    sig_summary = best_results['significance_level'].value_counts()\n",
    "    for level in ['Highly_Significant', 'Significant', 'Suggestive', 'Not_Significant']:\n",
    "        print(f\" - {level}: {sig_summary.get(level, 0)} genes\")\n",
    "    print(f\"\\n🏆 Top {TOP_RESULTS_TO_SHOW} results:\")\n",
    "    display_cols = ['Gene', 'Test_Type', 'P_value', 'neg_log10_p', 'NumVar', 'NumPolyVar']\n",
    "    sig_results = best_results[best_results['P_value'] < PRIMARY_THRESHOLD]\n",
    "    if len(sig_results) > 0:\n",
    "        print(sig_results[display_cols].head(TOP_RESULTS_TO_SHOW).to_string(index=False, float_format='%.2e'))\n",
    "    else:\n",
    "        print(\"No significant results found.\")\n",
    "        print(best_results[display_cols].head(TOP_RESULTS_TO_SHOW).to_string(index=False, float_format='%.2e'))\n",
    "\n",
    "# ── Save outputs to csv ─────────────────────────────\n",
    "\n",
    "def save_results(combined_df, best_results, cross_test_df, output_dir):\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(exist_ok=True, parents=True)\n",
    "    combined_df.to_csv(output_path / \"all_rare_variant_results.csv\", index=False)\n",
    "    best_results.to_csv(output_path / \"best_results_per_gene.csv\", index=False)\n",
    "    cross_test_df.to_csv(output_path / \"cross_test_significance_analysis.csv\", index=False)\n",
    "    significant_results = best_results[best_results['P_value'] < PRIMARY_THRESHOLD]\n",
    "    if len(significant_results) > 0:\n",
    "        significant_results.to_csv(output_path / \"significant_results.csv\", index=False)\n",
    "    multi_test_sig = cross_test_df[cross_test_df['Tests_Significant'] >= 2]\n",
    "    if len(multi_test_sig) > 0:\n",
    "        multi_test_sig.to_csv(output_path / \"multi_test_significant_genes.csv\", index=False)\n",
    "    print(f\"\\n✅ Results saved to: {output_dir}\")\n",
    "    return output_path\n",
    "\n",
    "# ── Main ─────────────────────────────\n",
    "def main():\n",
    "    # Check files exist\n",
    "    for file_path in [CMC_FILE, SKATO_FILE, VT_FILE]:\n",
    "        if not Path(file_path).exists():\n",
    "            print(f\"❌ Error: File not found - {file_path}\")\n",
    "            return\n",
    "    print(\"📥 Loading result files...\")\n",
    "    results_dict = load_and_process_files(CMC_FILE, SKATO_FILE, VT_FILE)\n",
    "    if results_dict is None:\n",
    "        print(\"❌ Failed to load one or more input files. Exiting.\")\n",
    "        return\n",
    "    # Process input datasets\n",
    "    for test_type, df in results_dict.items():\n",
    "        results_dict[test_type] = calculate_significance_metrics(df)\n",
    "    print(\"\\n🔄 Merging results...\")\n",
    "    combined_df = merge_results(results_dict)\n",
    "    print(\"⭐ Selecting best result per gene...\")\n",
    "    best_results = find_best_result_per_gene(combined_df)\n",
    "    print(\"🔗 Analysing cross-test significance...\")\n",
    "    cross_test_df, all_tests_sig, two_tests_sig, one_test_sig = analyze_cross_test_significance(combined_df)\n",
    "    # Console summary\n",
    "    generate_summary_report(results_dict, combined_df, best_results, cross_test_df,\n",
    "                            all_tests_sig, two_tests_sig, one_test_sig)\n",
    "    # Apply multiple testing correction to each test type\n",
    "    print(\"Applying multiple testing corrections...\")\n",
    "    for test_type, df in results_dict.items():\n",
    "        n_tests = len(df)\n",
    "        thresholds = calculate_significance_thresholds(n_tests)\n",
    "        results_dict[test_type] = apply_multiple_testing_correction(df)\n",
    "        # Summary of significant results\n",
    "        print(f\"\\n{test_type} Results Summary:\")\n",
    "        print(f\"  Total tests: {n_tests}\")\n",
    "        print(f\"  Nominal sig (p<0.05): {(df['P_value'] < 0.05).sum()}\")\n",
    "        print(f\"  Bonferroni sig: {(df['p_bonferroni'] < 0.05).sum() if 'p_bonferroni' in df else 'N/A'}\")\n",
    "        print(f\"  FDR sig: {(df['sig_fdr_bh']).sum() if 'sig_fdr_bh' in df else 'N/A'}\")\n",
    "    # For gene-level analysis (best result per gene)\n",
    "    print(\"\\nApplying gene-level multiple testing correction...\")\n",
    "    n_genes = len(best_results)\n",
    "    gene_thresholds = calculate_significance_thresholds(n_genes)\n",
    "    best_results_corrected = apply_multiple_testing_correction(best_results)\n",
    "    display_cols = ['Gene', 'Test_Type', 'P_value', 'p_fdr_bh', 'NumVar', 'NumPolyVar']\n",
    "    print(f\"\\nGene-level Results Summary:\")\n",
    "    print(f\"  Total genes: {n_genes}\")\n",
    "    print(f\"  Nominal sig (p<0.05): {(best_results['P_value'] < 0.05).sum()}\")\n",
    "    print(f\"  Bonferroni sig: {(best_results_corrected['p_bonferroni'] < 0.05).sum()}\")\n",
    "    print(f\"  FDR sig: {(best_results_corrected['sig_fdr_bh']).sum()}\")\n",
    "    # Update your reporting to include corrected results\n",
    "    print(f\"\\nTop significant genes (FDR corrected):\")\n",
    "    fdr_significant = best_results_corrected[best_results_corrected['sig_fdr_bh']]\n",
    "    if len(fdr_significant) > 0:\n",
    "        print(fdr_significant[display_cols].head(10).to_string(index=False, float_format='%.2e'))\n",
    "    else:\n",
    "        print(\"No genes significant after FDR correction\")\n",
    "        # Show top Bonferroni significant if any\n",
    "        bonf_significant = best_results_corrected[best_results_corrected['sig_bonferroni']]\n",
    "        if len(bonf_significant) > 0:\n",
    "            print(f\"\\nTop significant genes (Bonferroni corrected):\")\n",
    "            print(bonf_significant[display_cols].head(5).to_string(index=False, float_format='%.2e'))\n",
    "    # Save corrected results\n",
    "    best_results_corrected.to_csv(OUTPUT_DIR / \"best_results_per_gene_corrected.csv\", index=False)\n",
    "    # Additional reporting of multiple testing correction stats and lists\n",
    "    generate_correction_summary_report(best_results_corrected, OUTPUT_DIR)\n",
    "    # Save\n",
    "    output_path = save_results(combined_df, best_results, cross_test_df, OUTPUT_DIR)\n",
    "    print(\"\\n🏁 Analysis complete.\")\n",
    "    print(f\"- {len(all_tests_sig)} genes significant in ALL tests\")\n",
    "    print(f\"- {len(two_tests_sig)} genes significant in 2 tests\")\n",
    "    print(f\"- {len(one_test_sig)} genes significant in 1 test\")\n",
    "    print(f\"\\n📌 Priority genes (>=2 tests significant):\")\n",
    "    priority_genes = cross_test_df[cross_test_df['Tests_Significant'] >= 2]['Gene'].tolist()\n",
    "    if priority_genes:\n",
    "        for i, gene in enumerate(priority_genes[:MAX_GENES_TO_LIST], 1):\n",
    "            gene_info = cross_test_df[cross_test_df['Gene'] == gene].iloc[0]\n",
    "            print(f\"{i}. {gene} ({gene_info['Tests_Significant']} tests, min p = {gene_info['Min_Pvalue']:.2e})\")\n",
    "        if len(priority_genes) > MAX_GENES_TO_LIST:\n",
    "            print(f\"... and {len(priority_genes) - MAX_GENES_TO_LIST} more genes.\")\n",
    "    else:\n",
    "        print(\"No multi-test significant genes detected.\")\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "a4cf9024487f08c6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 05 Variant Extraction\n",
    "- Extract significant loci from VCF using bcftools\n",
    "- Apply allele frequency filters for rare variant validation\n",
    "- Generate RSID lists for candidate genes\n",
    "\n",
    "\n"
   ],
   "id": "2ea0031132a8fef4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# example of variant extraction premise\n",
    "\n",
    "# from Rvtests results\n",
    "# find variants in CDCA7L 7:21907041-21952042\n",
    "\n",
    "bcftools view -r 7:21907041-21952042 \"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/02_annotations/inputs/vcf/ADNI2_AD_CN_converted.vcf.gz\" \\\n",
    "  | bcftools view -i 'AF >0.005 && AF <=0.01' \\\n",
    "  > \"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/04_post_analysis/CDCA7L_ADNI_rare.vcf\"\n"
   ],
   "id": "ff525c3c4396716a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 05_post_analysis\n",
    "# i. extract variants from significant regions with bcftools\n",
    "\n",
    "\n",
    "##############################################################\n",
    "# USER-DEFINED INPUTS (EDIT HERE) #\n",
    "##############################################################\n",
    "\n",
    "# Input files (comment out unused to select input)\n",
    "SIGNIFICANT_GENES_FILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/04_post_analysis/multi_test_significant_genes.csv\"\n",
    "# SIGNIFICANT_GENES_FILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/04_post_analysis/significant_results.csv\"\n",
    "# SIGNIFICANT_GENES_FILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/04_post_analysis/best_results_per_gene.csv\"\n",
    "\n",
    "# Input VCF file\n",
    "VCF_FILE=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/02_dataset_conversion/ADNI2_AD_CN_converted.vcf.gz\"\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR=\"/mnt/c/Users/B00731414/OneDrive - Ulster University/6. Code/ADNI/5. Rvtests/05_variant_extraction\"\n",
    "\n",
    "# Allele frequency filter (rare variants)\n",
    "MIN_AF=\"0.005\"\n",
    "MAX_AF=\"0.01\"\n",
    "\n",
    "# Additional bcftools filters\n",
    "ADDITIONAL_FILTERS=\"\"   # e.g. \"&& QUAL>20 && DP>10\"\n",
    "\n",
    "# Processing options\n",
    "MAX_GENES_TO_PROCESS=\"20\"   # Leave empty to run all genes\n",
    "SKIP_EXISTING_FILES=\"true\"  # Skip existing files if true, overwrite if false\n",
    "\n",
    "##############################################################\n",
    "# DO NOT EDIT BELOW THIS LINE #\n",
    "##############################################################\n",
    "\n",
    "# ── Console Colours ─────────────────────────────\n",
    "RED='\\033[0;31m'\n",
    "GREEN='\\033[0;32m'\n",
    "YELLOW='\\033[1;33m'\n",
    "BLUE='\\033[0;34m'\n",
    "NC='\\033[0m' # No Colour\n",
    "\n",
    "\n",
    "# ── Dependency check ─────────────────────────────\n",
    "check_dependencies() {\n",
    "    echo -e \"${BLUE}🔍 Checking dependencies...${NC}\"\n",
    "    if ! command -v bcftools &>/dev/null; then\n",
    "        echo -e \"${RED}❌ Error: bcftools not found. Please install bcftools.${NC}\"\n",
    "        exit 1\n",
    "    fi\n",
    "    if ! command -v awk &>/dev/null; then\n",
    "        echo -e \"${RED}❌ Error: awk not found. Please install awk.${NC}\"\n",
    "        exit 1\n",
    "    fi\n",
    "    echo -e \"${GREEN}✅ All dependencies present.${NC}\"\n",
    "}\n",
    "\n",
    "\n",
    "# ── Parse genomic range ─────────────────────────────\n",
    "parse_genomic_range() {\n",
    "    local range_string=\"$1\"\n",
    "    range_string=$(echo \"$range_string\" | sed 's/\"//g' | cut -d',' -f1)\n",
    "    if [[ $range_string =~ ^([^:]+):([0-9]+)-([0-9]+)$ ]]; then\n",
    "        CHROM=\"${BASH_REMATCH[1]}\"\n",
    "        START=\"${BASH_REMATCH[2]}\"\n",
    "        END=\"${BASH_REMATCH[3]}\"\n",
    "        return 0\n",
    "    else\n",
    "        return 1\n",
    "    fi\n",
    "}\n",
    "\n",
    "\n",
    "# ── Extract variants for a gene ─────────────────────────────\n",
    "extract_variants_for_gene() {\n",
    "    local gene_name=\"$1\"\n",
    "    local chrom=\"$2\"\n",
    "    local start=\"$3\"\n",
    "    local end=\"$4\"\n",
    "\n",
    "    local output_file=\"${OUTPUT_DIR}/${gene_name}_ADNI_rare.vcf\"\n",
    "    local rsid_file=\"${OUTPUT_DIR}/${gene_name}_ADNI_rare_rsids.txt\"\n",
    "\n",
    "    # Skip pre-existing files\n",
    "    if [[ \"$SKIP_EXISTING_FILES\" == \"true\" && -f \"$output_file\" ]]; then\n",
    "        echo -e \"${YELLOW}⚠️  Skipping $gene_name - file already exists${NC}\"\n",
    "        return 0\n",
    "    fi\n",
    "\n",
    "    local region=\"${chrom}:${start}-${end}\"\n",
    "    local af_filter=\"AF >${MIN_AF} && AF <=${MAX_AF}\"\n",
    "    local full_filter=\"$af_filter ${ADDITIONAL_FILTERS}\"\n",
    "\n",
    "    echo -e \"${BLUE}📂 Extracting: $gene_name ($region)...${NC}\"\n",
    "\n",
    "    # Run bcftools\n",
    "    if bcftools view -r \"$region\" \"$VCF_FILE\" | bcftools view -i \"$full_filter\" > \"$output_file\" 2>/dev/null; then\n",
    "        if [[ -f \"$output_file\" ]]; then\n",
    "            local file_size=$(stat -c%s \"$output_file\" 2>/dev/null || echo \"0\")\n",
    "            local variant_count=$(grep -v '^#' \"$output_file\" 2>/dev/null | wc -l || echo \"0\")\n",
    "\n",
    "            if [[ $variant_count -gt 0 ]]; then\n",
    "                echo -e \"${GREEN}✅ Success: $variant_count variants extracted (${file_size} bytes).${NC}\"\n",
    "                echo \"$gene_name,Success,$variant_count variants (${file_size} bytes),${gene_name}_ADNI_rare.vcf,$chrom,$start,$end\" >> \"$results_file\"\n",
    "\n",
    "                # 🔹 Extract RSIDs into a separate txt file\n",
    "                awk '!/^#/ {print $3}' \"$output_file\" | grep -v '^\\.$' > \"$rsid_file\"\n",
    "                rsid_count=$(wc -l < \"$rsid_file\")\n",
    "                echo -e \"${GREEN}📄 RSID list created: $rsid_file (${rsid_count} IDs)${NC}\"\n",
    "\n",
    "            else\n",
    "                echo -e \"${YELLOW}ℹ️  Success: No variants matched AF filter.${NC}\"\n",
    "                echo \"$gene_name,Success,No variants found,${gene_name}_ADNI_rare.vcf,$chrom,$start,$end\" >> \"$results_file\"\n",
    "            fi\n",
    "\n",
    "        else\n",
    "            echo -e \"${RED}❌ Failed: Output file not created.${NC}\"\n",
    "            echo \"$gene_name,Failed,Output file not created,N/A,$chrom,$start,$end\" >> \"$results_file\"\n",
    "        fi\n",
    "    else\n",
    "        echo -e \"${RED}❌ Failed: bcftools command failed.${NC}\"\n",
    "        echo \"$gene_name,Failed,bcftools error,N/A,$chrom,$start,$end\" >> \"$results_file\"\n",
    "    fi\n",
    "}\n",
    "\n",
    "\n",
    "# ── Main ─────────────────────────────\n",
    "main() {\n",
    "    echo \"================================================\"\n",
    "    echo \"GENE VARIANT EXTRACTION\"\n",
    "    echo \"================================================\"\n",
    "    echo \"Input genes: $SIGNIFICANT_GENES_FILE\"\n",
    "    echo \"VCF file:    $VCF_FILE\"\n",
    "    echo \"Output dir:  $OUTPUT_DIR\"\n",
    "    echo \"AF filter:   $MIN_AF < AF <= $MAX_AF\"\n",
    "    [[ -n \"$ADDITIONAL_FILTERS\" ]] && echo \"Extra filters: $ADDITIONAL_FILTERS\"\n",
    "    [[ -n \"$MAX_GENES_TO_PROCESS\" ]] && echo \"Gene cap: $MAX_GENES_TO_PROCESS\"\n",
    "    echo \"Skip existing files: $SKIP_EXISTING_FILES\"\n",
    "    echo \"================================================\"\n",
    "\n",
    "    # Check tools\n",
    "    check_dependencies\n",
    "\n",
    "    # Validate files\n",
    "    [[ ! -f \"$SIGNIFICANT_GENES_FILE\" ]] && echo -e \"${RED}❌ Error: Input CSV missing.${NC}\" && exit 1\n",
    "    [[ ! -f \"$VCF_FILE\" ]] && echo -e \"${RED}❌ Error: VCF missing.${NC}\" && exit 1\n",
    "\n",
    "    mkdir -p \"$OUTPUT_DIR\"\n",
    "\n",
    "    # Log file\n",
    "    results_file=\"$OUTPUT_DIR/variant_extraction_results.csv\"\n",
    "    echo \"Gene,Status,Message,Output_File,Chromosome,Start,End\" > \"$results_file\"\n",
    "\n",
    "    # Identify columns\n",
    "    header_line=$(head -n 1 \"$SIGNIFICANT_GENES_FILE\")\n",
    "    echo \"📑 CSV header: $header_line\"\n",
    "\n",
    "    gene_col=$(echo \"$header_line\" | tr ',' '\\n' | grep -n \"Gene\" | cut -d':' -f1)\n",
    "    range_col=$(echo \"$header_line\" | tr ',' '\\n' | grep -n \"RANGE\" | cut -d':' -f1)\n",
    "    [[ -z \"$gene_col\" || -z \"$range_col\" ]] && echo -e \"${RED}❌ Gene/RANGE columns not found.${NC}\" && exit 1\n",
    "    echo \"✅ Found Gene @ col $gene_col, RANGE @ col $range_col\"\n",
    "\n",
    "    local processed_count=0\n",
    "\n",
    "    # Process CSV\n",
    "    tail -n +2 \"$SIGNIFICANT_GENES_FILE\" | while IFS= read -r line; do\n",
    "        [[ -n \"$MAX_GENES_TO_PROCESS\" && $processed_count -ge $MAX_GENES_TO_PROCESS ]] && break\n",
    "        IFS=',' read -ra FIELDS <<< \"$line\"\n",
    "        local gene_name=$(echo \"${FIELDS[$((gene_col-1))]}\" | sed 's/\"//g')\n",
    "        local range_string=$(echo \"${FIELDS[$((range_col-1))]}\" | sed 's/\"//g')\n",
    "\n",
    "        echo -e \"\\n🔬 Processing gene $((processed_count+1)): $gene_name\"\n",
    "        echo \"   Range: $range_string\"\n",
    "\n",
    "        if parse_genomic_range \"$range_string\"; then\n",
    "            echo \"   Parsed: $CHROM:$START-$END\"\n",
    "            extract_variants_for_gene \"$gene_name\" \"$CHROM\" \"$START\" \"$END\"\n",
    "        else\n",
    "            echo -e \"${RED}❌ Failed: Invalid genomic range '${range_string}'${NC}\"\n",
    "            echo \"$gene_name,Failed,Invalid range,N/A,N/A,N/A,N/A\" >> \"$results_file\"\n",
    "        fi\n",
    "        ((processed_count++))\n",
    "    done\n",
    "\n",
    "    echo -e \"\\n🏁 Pipeline complete.\"\n",
    "}\n",
    "\n",
    "\n",
    "# ── Run ─────────────────────────────\n",
    "main \"$@\"\n"
   ],
   "id": "bf7088c27f0ef3d6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
